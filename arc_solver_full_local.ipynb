{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "#  ARC Solver — Self-contained Kaggle Notebook\n",
    "# ============================================================\n",
    "import os, json, pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Recreate package folder\n",
    "pkg = Path('/kaggle/working/arc_solver'); pkg.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Write all source files from local copy\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# write to /kaggle/working/arc_solver/__init__.py",
    "open('/kaggle/working/arc_solver/__init__.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/__init__.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- Kaggle-aware configuration ----------\n",
    "_KAGGLE_INPUT = "/kaggle/input/arc-prize-2025"\n",
    "_DEFAULT_HOME = str(Path.home())\n",
    "\n",
    "if os.path.exists(_KAGGLE_INPUT):\n",
    "    _WORK = "/kaggle/working"\n",
    "    _SUB  = f"{_WORK}/submission.json"\n",
    "    _DATA = _KAGGLE_INPUT\n",
    "else:\n",
    "    _WORK = os.environ.get("ARC_WORK_DIR", f"{_DEFAULT_HOME}/arc_solver")\n",
    "    _SUB  = os.environ.get("ARC_SUBMISSION_PATH", f"{_WORK}/submission.json")\n",
    "    _DATA = os.environ.get("ARC_DATA_PATH", f"{_DEFAULT_HOME}/arc_data")\n",
    "\n",
    "WORK = Path(_WORK)\n",
    "SUBMISSION_PATH = Path(_SUB)\n",
    "DATA_PATH = Path(_DATA)\n",
    "# write to /kaggle/working/arc_solver/config.py",
    "open('/kaggle/working/arc_solver/config.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/config.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "# fetch_arc_datasets.py — unified dataset loader and merger\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from arc_solver.config import WORK\n",
    "\n",
    "TRAIN_PATH = WORK / "arc-agi_training_challenges.json"\n",
    "TEST_PATH  = WORK / "arc-agi_test_challenges.json"\n",
    "MERGED_PATH = WORK / "merged_dataset.json"\n",
    "\n",
    "def _load_json(path: Path):\n",
    "    """Load a JSON file; tolerate single dicts and empty content."""\n",
    "    if not path.exists():\n",
    "        return []\n",
    "    try:\n",
    "        text = path.read_text().strip()\n",
    "        if not text:\n",
    "            return []\n",
    "        data = json.loads(text)\n",
    "        if isinstance(data, dict):\n",
    "            return [data]\n",
    "        if isinstance(data, list):\n",
    "            return data\n",
    "    except Exception as e:\n",
    "        print(f"[WARN] Could not load {path.name}: {e}")\n",
    "    return []\n",
    "\n",
    "def fetch_arc_datasets():\n",
    "    """Load training and test datasets, then merge for unified use."""\n",
    "    train = _load_json(TRAIN_PATH)\n",
    "    test = _load_json(TEST_PATH)\n",
    "\n",
    "    # Filter malformed or empty tasks\n",
    "    train = [t for t in train if isinstance(t, dict) and "train" in t]\n",
    "    test  = [t for t in test if isinstance(t, dict) and "test" in t]\n",
    "\n",
    "    print(f"[INFO] Loaded {len(train)} training tasks, {len(test)} testing tasks.")\n",
    "\n",
    "    # Merge both for continuity learning\n",
    "    merged = train + test\n",
    "    if merged:\n",
    "        with open(MERGED_PATH, "w") as f:\n",
    "            json.dump(merged, f, indent=2)\n",
    "        print(f"[DATA] Merged {len(merged)} total tasks → {MERGED_PATH}")\n",
    "    else:\n",
    "        print("[DATA] No tasks to merge.")\n",
    "\n",
    "    return train, test\n",
    "\n",
    "if __name__ == "__main__":\n",
    "    tr, te = fetch_arc_datasets()\n",
    "    print("Training tasks:", len(tr))\n",
    "    print("Testing tasks:", len(te))\n",
    "# write to /kaggle/working/arc_solver/fetch_arc_datasets.py",
    "open('/kaggle/working/arc_solver/fetch_arc_datasets.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/fetch_arc_datasets.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from arc_solver.step24_check_submission import validate_and_fix\n",
    "#!/usr/bin/env python3\n",
    "# ============================================================\n",
    "# Main Pipeline — ARC Solver with Meta, Self-Correction, Amplifier, and Decay\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from arc_solver.config import WORK, SUBMISSION_PATH\n",
    "from arc_solver.step4_solve import solve_task\n",
    "from arc_solver.step10_meta_mutate import meta_mutate\n",
    "from arc_solver.step14_mutation_amplifier import amplify_mutations\n",
    "from arc_solver.step15_meta_decay import decay_meta_weights\n",
    "from arc_solver.step7_autolearn import summarize_ledger, update_meta_weights\n",
    "\n",
    "SUBMISSION_PATH = WORK / "submission.json"\n",
    "CONF_THRESH = 0.85\n",
    "MAX_CYCLES = 5\n",
    "\n",
    "def load_tasks():\n",
    "    merged = WORK / "merged_dataset.json"\n",
    "    with open(merged) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def run_cycle(tasks):\n",
    "    results = {}\n",
    "    confs = []\n",
    "    for task in tasks:\n",
    "        preds, conf = solve_task(task)\n",
    "        results[task.get("id", "unknown")] = preds\n",
    "        confs.append(conf)\n",
    "    return results, float(np.mean(confs))\n",
    "\n",
    "def main():\n",
    "    print("[INIT] Loading dataset...")\n",
    "    tasks = load_tasks()\n",
    "    last_conf = 0.0\n",
    "\n",
    "    for cycle in range(1, MAX_CYCLES + 1):\n",
    "        print(f"[CYCLE {cycle}] Running solver...")\n",
    "        results, avg_conf = run_cycle(tasks)\n",
    "        results, _fix_issues = validate_and_fix(results, tasks)\n",
    "        print(f"[SUBMIT-CHECK] {len(_fix_issues)} post-fix issues detected" if _fix_issues else "[SUBMIT-CHECK] OK")\n",
    "        print(f"[CYCLE {cycle}] Mean confidence = {avg_conf:.2f}")\n",
    "\n",
    "        if avg_conf >= CONF_THRESH:\n",
    "            print(f"[CYCLE {cycle}] Confidence threshold met ({avg_conf:.2f}). Stopping retrain.")\n",
    "            meta_mutate()\n",
    "            amplify_mutations(avg_conf)\n",
    "            decay_meta_weights(last_conf, avg_conf)\n",
    "            break\n",
    "        else:\n",
    "            print(f"[CYCLE {cycle}] Re-training...")\n",
    "            meta_mutate()\n",
    "            amplify_mutations(avg_conf)\n",
    "            decay_meta_weights(last_conf, avg_conf)\n",
    "\n",
    "        last_conf = avg_conf\n",
    "\n",
    "    ledger_summary = summarize_ledger()\n",
    "    print(f"[LEDGER SUMMARY] {ledger_summary}")\n",
    "    update_meta_weights()\n",
    "    from arc_solver.step19_meta_promoter import promote_replay_to_meta\n",
    "    promote_replay_to_meta(base_threshold=0.9)\n",
    "    from arc_solver.step20_meta_summary import record_summary\n",
    "    from arc_solver.step21_meta_rehearse import rehearse_meta\n",
    "    record_summary(threshold=0.801, promoted=10)\n",
    "    from arc_solver.step22_meta_diversify import diversify_meta\n",
    "    diversify_meta(target=24, min_new=8, max_shifts=2)\n",
    "    rehearse_meta(cap=24, diversity=0.5, min_sig_dist=0.4)\n",
    "\n",
    "    with open(SUBMISSION_PATH, "w") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(f"[DONE] Submission saved → {SUBMISSION_PATH}")\n",
    "\n",
    "if __name__ == "__main__":\n",
    "    main()\n",
    "# write to /kaggle/working/arc_solver/main_pipeline.py",
    "open('/kaggle/working/arc_solver/main_pipeline.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/main_pipeline.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "# observer.py — learns from previous solver attempts and ranks rule types\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "LEDGER_PATH = Path(__file__).parent / "observer_log.jsonl"\n",
    "\n",
    "def observe_event(event: dict):\n",
    "    """Append observer event to JSONL ledger."""\n",
    "    try:\n",
    "        with open(LEDGER_PATH, "a") as f:\n",
    "            f.write(json.dumps(event) + "\n")\n",
    "    except Exception as e:\n",
    "        print(f"[Observer] Write error: {e}")\n",
    "\n",
    "def analyze_observer():\n",
    "    """Aggregate observer data and return mean confidence by rule type."""\n",
    "    if not LEDGER_PATH.exists():\n",
    "        return {}\n",
    "    stats = defaultdict(lambda: {"count": 0, "mean_conf": 0.0})\n",
    "    try:\n",
    "        with open(LEDGER_PATH) as f:\n",
    "            for line in f:\n",
    "                e = json.loads(line.strip())\n",
    "                t = e.get("rule_type", "unknown")\n",
    "                c = float(e.get("confidence", 0.0))\n",
    "                stats[t]["count"] += 1\n",
    "                stats[t]["mean_conf"] += c\n",
    "        for t in stats:\n",
    "            stats[t]["mean_conf"] /= stats[t]["count"]\n",
    "    except Exception as e:\n",
    "        print(f"[Observer] Read error: {e}")\n",
    "    ranked = sorted(stats.items(), key=lambda x: x[1]["mean_conf"], reverse=True)\n",
    "    return {r[0]: r[1] for r in ranked}\n",
    "\n",
    "def get_top_rule_type():\n",
    "    """Return the top-performing rule type based on historical observer data."""\n",
    "    ranked = analyze_observer()\n",
    "    if not ranked:\n",
    "        return "unknown"\n",
    "    return next(iter(ranked.keys()))\n",
    "\n",
    "def get_rule_weights() -> dict:\n",
    "    """\n",
    "    Compute normalized weighting factors for each rule type\n",
    "    based on cumulative mean confidence recorded so far.\n",
    "    Returned dict example: {'color_map': 1.2, 'shift_map': 0.8}\n",
    "    """\n",
    "    ranked = analyze_observer()\n",
    "    if not ranked:\n",
    "        return {}\n",
    "    # normalize mean_conf into weight factors\n",
    "    max_conf = max(v["mean_conf"] for v in ranked.values() if v["mean_conf"] > 0)\n",
    "    if max_conf == 0:\n",
    "        return {t: 1.0 for t in ranked}\n",
    "    return {t: round(v["mean_conf"] / max_conf, 3) for t, v in ranked.items()}\n",
    "# write to /kaggle/working/arc_solver/observer.py",
    "open('/kaggle/working/arc_solver/observer.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/observer.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "# step0_utils.py — core numeric and progress utilities\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "\n",
    "def to_np(grid):\n",
    "    """Convert grid (list of lists) to NumPy array."""\n",
    "    return np.array(grid, dtype=np.int64)\n",
    "\n",
    "def to_grid(array):\n",
    "    """Convert NumPy array back to grid (list of lists)."""\n",
    "    return array.tolist()\n",
    "\n",
    "def fit_to_shape(a: np.ndarray, out_h: int, out_w: int) -> np.ndarray:\n",
    "    """Resize by nearest replication."""\n",
    "    in_h, in_w = a.shape\n",
    "    out = np.zeros((out_h, out_w), dtype=a.dtype)\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "            out[i, j] = a[i * in_h // out_h, j * in_w // out_w]\n",
    "    return out\n",
    "\n",
    "def scale_nearest(a: np.ndarray, scale: float) -> np.ndarray:\n",
    "    """Scale an array by nearest-neighbor interpolation."""\n",
    "    out_h = max(1, int(round(a.shape[0] * scale)))\n",
    "    out_w = max(1, int(round(a.shape[1] * scale)))\n",
    "    return fit_to_shape(a, out_h, out_w)\n",
    "\n",
    "def ensure_integrity(a: np.ndarray) -> np.ndarray:\n",
    "    """Clip invalid values and ensure 2D int64 array."""\n",
    "    a = np.nan_to_num(a, nan=0).astype(np.int64)\n",
    "    if a.ndim != 2:\n",
    "        a = a.reshape((a.shape[0], -1))\n",
    "    return np.clip(a, 0, 9)\n",
    "\n",
    "def compute_confidence(pred: np.ndarray, target: np.ndarray) -> float:\n",
    "    """Compute confidence as elementwise accuracy."""\n",
    "    pred = ensure_integrity(pred)\n",
    "    target = ensure_integrity(target)\n",
    "    if pred.shape != target.shape:\n",
    "        return 0.0\n",
    "    total = pred.size\n",
    "    correct = np.sum(pred == target)\n",
    "    return round(float(correct) / total, 3)\n",
    "\n",
    "def progress_bar(conf: float, width: int = 40):\n",
    "    """Print inline confidence progress bar."""\n",
    "    filled = int(conf * width)\n",
    "    bar = "█" * filled + "-" * (width - filled)\n",
    "    sys.stdout.write(f"\r[{bar}] {conf*100:5.1f}%")\n",
    "    sys.stdout.flush()\n",
    "# write to /kaggle/working/arc_solver/step0_utils.py",
    "open('/kaggle/working/arc_solver/step0_utils.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step0_utils.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "# step10_meta_mutate.py — heuristic meta-mutation for cached rules\n",
    "import json, random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "WORK = Path("/data/data/com.termux/files/home/arc_solver")\n",
    "CACHE_PATH = WORK / "rule_cache.json"\n",
    "\n",
    "def _load_cache():\n",
    "    if CACHE_PATH.exists():\n",
    "        try:\n",
    "            with open(CACHE_PATH) as f:\n",
    "                return json.load(f)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return {}\n",
    "\n",
    "def _save_cache(data):\n",
    "    with open(CACHE_PATH, "w") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "def mutate_color_map(cmap: dict) -> dict:\n",
    "    """Randomly perturb color map values within range [0,9]."""\n",
    "    mutated = dict(cmap)\n",
    "    if not mutated:\n",
    "        return mutated\n",
    "    for k in list(mutated.keys()):\n",
    "        if random.random() < 0.3:  # mutate 30% of entries\n",
    "            mutated[k] = int((mutated[k] + random.choice([-1, 1])) % 10)\n",
    "    return mutated\n",
    "\n",
    "def mutate_rule(rule: dict) -> dict:\n",
    "    """Create a mutated copy of a rule."""\n",
    "    new_rule = dict(rule)\n",
    "    if "color_map" in new_rule:\n",
    "        new_rule["color_map"] = mutate_color_map(new_rule["color_map"])\n",
    "    if "confidence" in new_rule:\n",
    "        new_rule["confidence"] = round(float(new_rule["confidence"]) * random.uniform(0.9, 1.1), 3)\n",
    "    return new_rule\n",
    "\n",
    "def meta_mutate():\n",
    "    """Apply mutation to cached rules for exploration."""\n",
    "    cache = _load_cache()\n",
    "    if not cache:\n",
    "        print("[MUTATE] No cached rules to mutate.")\n",
    "        return\n",
    "    mutated_count = 0\n",
    "    for key, rec in list(cache.items()):\n",
    "        rule = rec.get("rule")\n",
    "        if not rule:\n",
    "            continue\n",
    "        if random.random() < 0.5:  # mutate half\n",
    "            cache[key]["rule"] = mutate_rule(rule)\n",
    "            mutated_count += 1\n",
    "    _save_cache(cache)\n",
    "    print(f"[MUTATE] Mutated {mutated_count}/{len(cache)} cached rules.")\n",
    "# write to /kaggle/working/arc_solver/step10_meta_mutate.py",
    "open('/kaggle/working/arc_solver/step10_meta_mutate.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step10_meta_mutate.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "# step11_self_correct.py — self-validation and corrective rule synthesis\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from arc_solver.step0_utils import ensure_integrity\n",
    "from arc_solver.step8_memory_cache import update_cache\n",
    "from arc_solver.step7_autolearn import log_event\n",
    "\n",
    "WORK = Path("/data/data/com.termux/files/home/arc_solver")\n",
    "CORR_PATH = WORK / "self_corrections.json"\n",
    "\n",
    "def validate_prediction(pred, target):\n",
    "    """Return accuracy score for grid comparison."""\n",
    "    pred = ensure_integrity(np.array(pred))\n",
    "    target = ensure_integrity(np.array(target))\n",
    "    if pred.shape != target.shape:\n",
    "        return 0.0\n",
    "    return float(np.mean(pred == target))\n",
    "\n",
    "def generate_correction(pred, target):\n",
    "    """Infer corrective color mapping from mismatched cells."""\n",
    "    pred = ensure_integrity(np.array(pred))\n",
    "    target = ensure_integrity(np.array(target))\n",
    "    diff_mask = pred != target\n",
    "    cmap = {}\n",
    "    for v in np.unique(pred[diff_mask]):\n",
    "        if v in target:\n",
    "            cmap[int(v)] = int(np.bincount(target[diff_mask]).argmax())\n",
    "    conf = round(validate_prediction(pred, target), 3)\n",
    "    return {"type": "color_map_fix", "color_map": cmap, "confidence": conf}\n",
    "\n",
    "def apply_self_correction(task, preds):\n",
    "    """Compare predictions to known outputs; update cache if fix found."""\n",
    "    corrections = []\n",
    "    for i, pair in enumerate(task.get("train", [])):\n",
    "        if "output" not in pair:\n",
    "            continue\n",
    "        score = validate_prediction(preds[0], pair["output"])\n",
    "        if score < 1.0:\n",
    "            fix = generate_correction(preds[0], pair["output"])\n",
    "            update_cache(task, fix, fix["confidence"])\n",
    "            log_event(fix["type"], fix["confidence"])\n",
    "            corrections.append(fix)\n",
    "    if corrections:\n",
    "        with open(CORR_PATH, "w") as f:\n",
    "            json.dump(corrections, f, indent=2)\n",
    "        print(f"[CORRECT] Applied {len(corrections)} fixes.")\n",
    "    return corrections\n",
    "# write to /kaggle/working/arc_solver/step11_self_correct.py",
    "open('/kaggle/working/arc_solver/step11_self_correct.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step11_self_correct.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    """"\n",
    "step12_rule_blender.py — blend multiple ARC rules into a single stronger rule.\n",
    "\n",
    "We support (for now):\n",
    "- color_map\n",
    "- color_map_fix\n",
    "\n",
    "Strategy:\n",
    "1. Normalize all rule types to a color-map-like structure.\n",
    "2. Weight each candidate by its confidence.\n",
    "3. For each input color, pick the output color with the highest total weight.\n",
    """"\n",
    "\n",
    "from __future__ import annotations\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def _rule_to_color_map(rule: Dict[str, Any]) -> Dict[int, int]:\n",
    "    """Convert different rule types to a canonical color_map."""\n",
    "    if not rule:\n",
    "        return {}\n",
    "    rtype = rule.get("type", "color_map")\n",
    "    cmap = {}\n",
    "\n",
    "    if rtype in ("color_map", "color_map_fix"):\n",
    "        raw = rule.get("color_map", {})\n",
    "        # normalize possible numpy/int types\n",
    "        for k, v in raw.items():\n",
    "            ck = int(k)\n",
    "            cv = int(v)\n",
    "            cmap[ck] = cv\n",
    "    else:\n",
    "        # fallback – unknown rule type\n",
    "        pass\n",
    "    return cmap\n",
    "\n",
    "def blend_rules(rules: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    """\n",
    "    Blend multiple rules into a single color_map rule.\n",
    "    rules: list of dicts, each should have 'type', 'color_map', 'confidence'\n",
    "    """\n",
    "    if not rules:\n",
    "        return {"type": "color_map", "color_map": {}, "confidence": 0.0}\n",
    "\n",
    "    # aggregate votes per input color\n",
    "    votes: Dict[int, Dict[int, float]] = {}\n",
    "    total_conf = 0.0\n",
    "\n",
    "    for r in rules:\n",
    "        conf = float(r.get("confidence", 0.0))\n",
    "        total_conf += conf\n",
    "        cmap = _rule_to_color_map(r)\n",
    "        for inc, outc in cmap.items():\n",
    "            inc = int(inc)\n",
    "            outc = int(outc)\n",
    "            if inc not in votes:\n",
    "                votes[inc] = {}\n",
    "            votes[inc][outc] = votes[inc].get(outc, 0.0) + conf\n",
    "\n",
    "    # pick the best target color per input color\n",
    "    blended_cmap: Dict[int, int] = {}\n",
    "    for inc, out_votes in votes.items():\n",
    "        # sort by weight desc\n",
    "        best_out = max(out_votes.items(), key=lambda x: x[1])[0]\n",
    "        blended_cmap[inc] = int(best_out)\n",
    "\n",
    "    # confidence of the blend = avg of contributors\n",
    "    blend_conf = round(total_conf / max(len(rules), 1), 3)\n",
    "\n",
    "    return {\n",
    "        "type": "color_map_blend",\n",
    "        "color_map": blended_cmap,\n",
    "        "confidence": blend_conf,\n",
    "        "sources": [r.get("type", "unknown") for r in rules],\n",
    "    }\n",
    "# write to /kaggle/working/arc_solver/step12_rule_blender.py",
    "open('/kaggle/working/arc_solver/step12_rule_blender.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step12_rule_blender.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    """"\n",
    "step12_self_corrector.py — tolerant self-correction engine.\n",
    "Accepts either dict or list[dict] color_maps, never raises attribute errors.\n",
    """"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def apply_self_correction(task: dict, color_maps) -> list[dict]:\n",
    "    """Generate corrective color maps safely from training pairs."""\n",
    "    fixes = []\n",
    "    try:\n",
    "        train_pairs = task.get("train", [])\n",
    "        # Normalize color_maps into list of dicts\n",
    "        if isinstance(color_maps, dict):\n",
    "            color_maps = [color_maps]\n",
    "        elif not isinstance(color_maps, list):\n",
    "            color_maps = []\n",
    "\n",
    "        for cmap in color_maps:\n",
    "            if not isinstance(cmap, dict):\n",
    "                continue\n",
    "            for pair in train_pairs:\n",
    "                inp = np.array(pair["input"], dtype=int)\n",
    "                out = np.array(pair["output"], dtype=int)\n",
    "                mismatch = (inp != out)\n",
    "                if np.any(mismatch):\n",
    "                    corrected = dict(cmap)\n",
    "                    for ci in np.unique(inp[mismatch]):\n",
    "                        co = np.bincount(out[inp == ci]).argmax()\n",
    "                        corrected[int(ci)] = int(co)\n",
    "                    fixes.append(corrected)\n",
    "        if fixes:\n",
    "            print(f"[CORRECT] Applied {len(fixes)} fixes.")\n",
    "    except Exception as e:\n",
    "        print(f"[CORRECT] Error: {e}")\n",
    "    return fixes\n",
    "# write to /kaggle/working/arc_solver/step12_self_corrector.py",
    "open('/kaggle/working/arc_solver/step12_self_corrector.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step12_self_corrector.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    """"\n",
    "step13_cross_generalizer.py — derive meta-rules across all cached and learned rules.\n",
    "\n",
    "Purpose:\n",
    "- Scan cached rules (from step8_memory_cache)\n",
    "- Scan memory ledger (from step7_autolearn)\n",
    "- Cluster similar color maps\n",
    "- Average confidence and build cross-task meta-rules\n",
    "- Save into meta_cache.json for future preloading\n",
    """"\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any\n",
    "from collections import defaultdict\n",
    "\n",
    "WORK = Path("/data/data/com.termux/files/home/arc_solver")\n",
    "CACHE_PATH = WORK / "cache.json"\n",
    "MEM_PATH = WORK / "autolearn_memory.json"\n",
    "META_PATH = WORK / "meta_cache.json"\n",
    "\n",
    "\n",
    "def _load_json(path: Path) -> Any:\n",
    "    if not path.exists():\n",
    "        return {}\n",
    "    try:\n",
    "        with open(path, "r") as f:\n",
    "            return json.load(f)\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def _save_json(path: Path, data: Any):\n",
    "    with open(path, "w") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "\n",
    "def _color_map_distance(map1: Dict[str, int], map2: Dict[str, int]) -> float:\n",
    "    """Simple symmetric distance metric between two color maps."""\n",
    "    keys = set(map1.keys()) | set(map2.keys())\n",
    "    if not keys:\n",
    "        return 0.0\n",
    "    diff = 0\n",
    "    for k in keys:\n",
    "        v1 = map1.get(k, -1)\n",
    "        v2 = map2.get(k, -1)\n",
    "        diff += (v1 != v2)\n",
    "    return diff / len(keys)\n",
    "\n",
    "\n",
    "def _merge_maps(maps: List[Dict[str, int]]) -> Dict[str, int]:\n",
    "    """Average vote per input color across multiple maps."""\n",
    "    tally = defaultdict(lambda: defaultdict(int))\n",
    "    for cmap in maps:\n",
    "        for k, v in cmap.items():\n",
    "            tally[k][v] += 1\n",
    "    merged = {}\n",
    "    for k, counts in tally.items():\n",
    "        best_v = max(counts.items(), key=lambda x: x[1])[0]\n",
    "        merged[k] = best_v\n",
    "    return {int(k): int(v) for k, v in merged.items()}\n",
    "\n",
    "\n",
    "def build_meta_rules() -> Dict[str, Any]:\n",
    "    """Aggregate all cached and memory rules into generalized meta-rules."""\n",
    "    cache = _load_json(CACHE_PATH)\n",
    "    memory = _load_json(MEM_PATH)\n",
    "    all_rules = []\n",
    "\n",
    "    # --- collect rules from cache ---\n",
    "    for tid, rec in cache.items():\n",
    "        rule = rec.get("rule")\n",
    "        if rule and isinstance(rule, dict):\n",
    "            cmap = rule.get("color_map", {})\n",
    "            conf = float(rule.get("confidence", 0.0))\n",
    "            all_rules.append({"type": rule.get("type", "unknown"), "color_map": cmap, "confidence": conf})\n",
    "\n",
    "    # --- collect from memory ---\n",
    "    for rtype, rec in memory.items():\n",
    "        if isinstance(rec, dict):\n",
    "            conf = float(rec.get("mean", rec.get("mean_conf", 0.0)))\n",
    "            if "color_map" in rec:\n",
    "                all_rules.append({"type": rtype, "color_map": rec["color_map"], "confidence": conf})\n",
    "\n",
    "    # --- group similar maps ---\n",
    "    clusters: List[List[Dict[str, Any]]] = []\n",
    "    for rule in all_rules:\n",
    "        placed = False\n",
    "        for cluster in clusters:\n",
    "            if _color_map_distance(rule["color_map"], cluster[0]["color_map"]) < 0.3:\n",
    "                cluster.append(rule)\n",
    "                placed = True\n",
    "                break\n",
    "        if not placed:\n",
    "            clusters.append([rule])\n",
    "\n",
    "    # --- merge each cluster ---\n",
    "    meta_rules = {}\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        merged_cmap = _merge_maps([r["color_map"] for r in cluster])\n",
    "        avg_conf = round(float(np.mean([r["confidence"] for r in cluster])), 3)\n",
    "        meta_rules[f"meta_rule_{i+1}"] = {\n",
    "            "type": "color_map_meta",\n",
    "            "color_map": merged_cmap,\n",
    "            "confidence": avg_conf,\n",
    "            "sources": [r["type"] for r in cluster],\n",
    "            "size": len(cluster),\n",
    "        }\n",
    "\n",
    "    _save_json(META_PATH, meta_rules)\n",
    "    print(f"[META-GEN] Built {len(meta_rules)} meta-rules → {META_PATH}")\n",
    "    return meta_rules\n",
    "\n",
    "\n",
    "if __name__ == "__main__":\n",
    "    meta = build_meta_rules(); print("[META-LINK] Imported self-corrected color maps into meta-cache")\n",
    "    print(json.dumps(meta, indent=2))\n",
    "# write to /kaggle/working/arc_solver/step13_cross_generalizer.py",
    "open('/kaggle/working/arc_solver/step13_cross_generalizer.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step13_cross_generalizer.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "# ============================================================\n",
    "# STEP 14 — Mutation Amplifier (safe, JSON-consistent)\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "CACHE_PATH = Path.home() / "arc_solver" / "cache.json"\n",
    "MUT_PATH   = Path.home() / "arc_solver" / "mutations.json"\n",
    "\n",
    "\n",
    "def _load_json(path):\n",
    "    if not path.exists():\n",
    "        return {}\n",
    "    try:\n",
    "        with open(path) as f:\n",
    "            data = json.load(f)\n",
    "            if isinstance(data, dict):\n",
    "                return data\n",
    "            if isinstance(data, list):\n",
    "                # convert legacy list into dict entries\n",
    "                return {f"task_{i:05d}": {"best_rule": v, "confidence": 0.5} for i, v in enumerate(data)}\n",
    "            return {}\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def _save_json(path, data):\n",
    "    """Write sanitized JSON"""\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, "w") as f:\n",
    "        json.dump(_json_safe(data), f, indent=2)\n",
    "\n",
    "\n",
    "def _json_safe(obj):\n",
    "    """Recursively make NumPy / set / tuple JSON-safe"""\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: _json_safe(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, (list, tuple, set)):\n",
    "        return [_json_safe(v) for v in obj]\n",
    "    elif isinstance(obj, (np.generic,)):\n",
    "        return obj.item()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "\n",
    "def amplify_mutations(avg_conf: float):\n",
    "    """\n",
    "    Strengthen all cached rules proportionally to global confidence.\n",
    "    Repairs bad cache types before use.\n",
    "    """\n",
    "    cache = _load_json(CACHE_PATH)\n",
    "    if not cache:\n",
    "        print("[MUTATE] No cached rules to amplify.")\n",
    "        return\n",
    "\n",
    "    fixed_cache = {}\n",
    "    mutations = {}\n",
    "\n",
    "    for k, rec in cache.items():\n",
    "        # --- normalize record type ---\n",
    "        if isinstance(rec, list):\n",
    "            rec = {"best_rule": rec, "confidence": 0.5}\n",
    "        elif not isinstance(rec, dict):\n",
    "            rec = {"best_rule": [], "confidence": 0.0}\n",
    "\n",
    "        conf = float(rec.get("confidence", 0.0))\n",
    "        boost = (conf + avg_conf) / 2.0\n",
    "        rec["confidence"] = round(boost, 3)\n",
    "\n",
    "        fixed_cache[k] = rec\n",
    "        mutations[k] = {"type": "amplified", "boost": boost}\n",
    "\n",
    "    _save_json(CACHE_PATH, fixed_cache)\n",
    "    _save_json(MUT_PATH, mutations)\n",
    "    print(f"[MUTATE] Amplified {len(fixed_cache)} rules. Mean boost={avg_conf:.3f}")\n",
    "\n",
    "\n",
    "if __name__ == "__main__":\n",
    "    amplify_mutations(0.5)\n",
    "# write to /kaggle/working/arc_solver/step14_mutation_amplifier.py",
    "open('/kaggle/working/arc_solver/step14_mutation_amplifier.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step14_mutation_amplifier.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    """"\n",
    "step15_meta_decay.py\n",
    "Dampens runaway meta weights and rewards genuine improvement.\n",
    """"\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "WORK = Path("/data/data/com.termux/files/home/arc_solver")\n",
    "META_PATH = WORK / "meta_weights.json"\n",
    "\n",
    "def _load_meta():\n",
    "    if META_PATH.exists():\n",
    "        try:\n",
    "            with open(META_PATH) as f:\n",
    "                return json.load(f)\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def _save_meta(meta: dict):\n",
    "    with open(META_PATH, "w") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "def decay_meta_weights(last_conf: float, avg_conf: float):\n",
    "    """Apply decay or recovery based on progress."""\n",
    "    meta = _load_meta()\n",
    "    if not meta:\n",
    "        return\n",
    "\n",
    "    improved = avg_conf > last_conf\n",
    "    for k, v in list(meta.items()):\n",
    "        v = float(v)\n",
    "        if improved:\n",
    "            # gentle recovery when performance rises\n",
    "            v = min(v * 1.02, 1.6)\n",
    "        else:\n",
    "            # decay if stagnant or declining\n",
    "            v = max(v * 0.97, 0.8)\n",
    "        meta[k] = round(v, 3)\n",
    "\n",
    "    _save_meta(meta)\n",
    "    tag = "RECOVER" if improved else "DECAY"\n",
    "    print(f"[META-{tag}] Adjusted meta weights → {meta}")\n",
    "# write to /kaggle/working/arc_solver/step15_meta_decay.py",
    "open('/kaggle/working/arc_solver/step15_meta_decay.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step15_meta_decay.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from typing import Optional\n",
    "\n",
    "def _mode_color(a: np.ndarray, minlen: int = 10) -> int:\n",
    "    if a.size == 0:\n",
    "        return 0\n",
    "    vals = a.ravel()\n",
    "    b = np.bincount(vals, minlength=max(10, minlen))\n",
    "    return int(np.argmax(b))\n",
    "\n",
    "def _fit_to_shape(a: np.ndarray, H: int, W: int, fill: Optional[int] = None) -> np.ndarray:\n",
    "    """Pad/crop to (H,W). Top-left anchor. Fill with mode if not given."""\n",
    "    ah, aw = a.shape\n",
    "    if fill is None:\n",
    "        fill = _mode_color(a)\n",
    "    out = np.full((H, W), fill, dtype=a.dtype)\n",
    "    h = min(H, ah); w = min(W, aw)\n",
    "    if h > 0 and w > 0:\n",
    "        out[:h, :w] = a[:h, :w]\n",
    "    return out\n",
    "\n",
    "def _shift2d_safe(a: np.ndarray, dx: int, dy: int, fill: int = 0) -> np.ndarray:\n",
    "    """Translate array by (dx,dy) with safe intersection math."""\n",
    "    H, W = a.shape\n",
    "    out = np.full((H, W), fill, dtype=a.dtype)\n",
    "    # source region\n",
    "    sx0 = max(0, -dx); sx1 = min(H, H - dx)\n",
    "    sy0 = max(0, -dy); sy1 = min(W, W - dy)\n",
    "    # destination region\n",
    "    dx0 = max(0, dx); dx1 = dx0 + (sx1 - sx0)\n",
    "    dy0 = max(0, dy); dy1 = dy0 + (sy1 - sy0)\n",
    "    if sx1 > sx0 and sy1 > sy0:\n",
    "        out[dx0:dx1, dy0:dy1] = a[sx0:sx1, sy0:sy1]\n",
    "    return out\n",
    "\n",
    "def detect_structure(inp: np.ndarray, out: np.ndarray) -> np.ndarray:\n",
    "    """\n",
    "    Safe structural pass:\n",
    "      1) align shapes to out.shape via pad/crop\n",
    "      2) try small translations on the aligned input\n",
    "      3) fall back to aligned input if no exact match\n",
    "    """\n",
    "    outH, outW = out.shape\n",
    "    fill = _mode_color(out)\n",
    "    a = _fit_to_shape(inp, outH, outW, fill)\n",
    "    if np.array_equal(a, out):\n",
    "        return a\n",
    "    for dx in range(-3, 4):\n",
    "        for dy in range(-3, 4):\n",
    "            cand = _shift2d_safe(a, dx, dy, fill)\n",
    "            if np.array_equal(cand, out):\n",
    "                return cand\n",
    "    return a\n",
    "# write to /kaggle/working/arc_solver/step17_structural_generalizer.py",
    "open('/kaggle/working/arc_solver/step17_structural_generalizer.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step17_structural_generalizer.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "# ============================================================\n",
    "# step18_meta_replay.py — Meta-Ledger Replay Memory\n",
    "# Stores and reuses past high-confidence rules to stabilize learning.\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "WORK = Path("/data/data/com.termux/files/home/arc_solver")\n",
    "REPLAY_PATH = WORK / "meta_replay.json"\n",
    "MAX_MEMORY = 10  # max stored entries\n",
    "\n",
    "# ============================================================\n",
    "# Replay Buffer Operations\n",
    "# ============================================================\n",
    "\n",
    "def _load_replay() -> list:\n",
    "    if REPLAY_PATH.exists():\n",
    "        try:\n",
    "            with open(REPLAY_PATH) as f:\n",
    "                return json.load(f)\n",
    "        except Exception:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def _save_replay(mem: list):\n",
    "    with open(REPLAY_PATH, "w") as f:\n",
    "        json.dump(mem[-MAX_MEMORY:], f, indent=2)\n",
    "\n",
    "# ============================================================\n",
    "# Core Functions\n",
    "# ============================================================\n",
    "\n",
    "def record_replay(rule_type: str, color_map: dict, confidence: float):\n",
    "    """Store a new rule snapshot with confidence."""\n",
    "    mem = _load_replay()\n",
    "    entry = {\n",
    "        "rule_type": rule_type,\n",
    "        "color_map": {int(k): int(v) for k, v in color_map.items()},\n",
    "        "confidence": round(float(confidence), 3)\n",
    "    }\n",
    "    mem.append(entry)\n",
    "    _save_replay(mem)\n",
    "    print(f"[REPLAY] Stored rule_type={rule_type} conf={confidence:.3f}")\n",
    "\n",
    "def fetch_top_replay(threshold: float = 0.8) -> dict:\n",
    "    """Retrieve highest-confidence rule above threshold."""\n",
    "    mem = _load_replay()\n",
    "    if not mem:\n",
    "        return {}\n",
    "    mem_sorted = sorted(mem, key=lambda x: x["confidence"], reverse=True)\n",
    "    best = mem_sorted[0]\n",
    "    if best["confidence"] >= threshold:\n",
    "        print(f"[REPLAY] Using top replay rule conf={best['confidence']}")\n",
    "        return best\n",
    "    return {}\n",
    "# write to /kaggle/working/arc_solver/step18_meta_replay.py",
    "open('/kaggle/working/arc_solver/step18_meta_replay.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step18_meta_replay.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "# ============================================================\n",
    "# step19_meta_promoter.py — Adaptive Meta Promotion System\n",
    "# Dynamically adjusts threshold based on average replay confidence\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "import statistics\n",
    "from pathlib import Path\n",
    "\n",
    "WORK = Path("/data/data/com.termux/files/home/arc_solver")\n",
    "REPLAY_PATH = WORK / "meta_replay.json"\n",
    "META_PATH = WORK / "meta_cache.json"\n",
    "\n",
    "def _load_json(path: Path):\n",
    "    if path.exists():\n",
    "        try:\n",
    "            with open(path) as f:\n",
    "                return json.load(f)\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def _save_json(path: Path, data: dict):\n",
    "    with open(path, "w") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "def promote_replay_to_meta(base_threshold: float = 0.9):\n",
    "    """Promote replayed rules with adaptive confidence threshold."""\n",
    "    replay = _load_json(REPLAY_PATH)\n",
    "    meta = _load_json(META_PATH)\n",
    "    promoted = 0\n",
    "\n",
    "    if not isinstance(replay, list) or not replay:\n",
    "        print("[PROMOTE] No replay data.")\n",
    "        return\n",
    "\n",
    "    # Compute adaptive threshold\n",
    "    confs = [float(r.get("confidence", 0)) for r in replay if "confidence" in r]\n",
    "    mean_conf = statistics.mean(confs)\n",
    "    std_conf = statistics.pstdev(confs) if len(confs) > 1 else 0\n",
    "    dynamic_thresh = max(base_threshold * 0.8, mean_conf + 0.25 * std_conf)\n",
    "    dynamic_thresh = round(dynamic_thresh, 3)\n",
    "\n",
    "    for entry in replay:\n",
    "        conf = float(entry.get("confidence", 0))\n",
    "        if conf >= dynamic_thresh:\n",
    "            rid = f"meta_promote_{len(meta)+1}"\n",
    "            meta[rid] = {\n",
    "                "type": f"{entry.get('rule_type', 'unknown')}_meta",\n",
    "                "color_map": entry.get("color_map", {}),\n",
    "                "confidence": conf,\n",
    "                "source": "adaptive_replay",\n",
    "            }\n",
    "            promoted += 1\n",
    "\n",
    "    if promoted:\n",
    "        _save_json(META_PATH, meta)\n",
    "        print(f"[PROMOTE] Promoted {promoted} replay rules → meta_cache.json (threshold={dynamic_thresh})")\n",
    "    else:\n",
    "        print(f"[PROMOTE] No rules passed threshold ({dynamic_thresh}).")\n",
    "# write to /kaggle/working/arc_solver/step19_meta_promoter.py",
    "open('/kaggle/working/arc_solver/step19_meta_promoter.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step19_meta_promoter.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# arc_solver/step1_objects.py\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "from arc_solver.step0_utils import ensure_integrity\n",
    "\n",
    "def find_objects(grid: np.ndarray) -> List[Dict]:\n",
    "    """\n",
    "    Find connected non-zero pixel clusters (4-neighbor).\n",
    "    Adds:\n",
    "      • bbox\n",
    "      • centroid (y,x)\n",
    "      • dominant color\n",
    "      • rotation / mirror signatures\n",
    "    """\n",
    "    g = ensure_integrity(grid)\n",
    "    h, w = g.shape\n",
    "    visited = np.zeros((h, w), dtype=bool)\n",
    "    objects = []\n",
    "    obj_id = 0\n",
    "\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            if g[y, x] == 0 or visited[y, x]:\n",
    "                continue\n",
    "            stack = [(y, x)]\n",
    "            visited[y, x] = True\n",
    "            pixels = []\n",
    "            color_counts = {}\n",
    "            y1 = y2 = y\n",
    "            x1 = x2 = x\n",
    "\n",
    "            while stack:\n",
    "                cy, cx = stack.pop()\n",
    "                pixels.append((cy, cx))\n",
    "                val = int(g[cy, cx])\n",
    "                color_counts[val] = color_counts.get(val, 0) + 1\n",
    "                y1, y2 = min(y1, cy), max(y2, cy)\n",
    "                x1, x2 = min(x1, cx), max(x2, cx)\n",
    "                for ny, nx in ((cy-1,cx),(cy+1,cx),(cy,cx-1),(cy,cx+1)):\n",
    "                    if 0<=ny<h and 0<=nx<w and not visited[ny,nx] and g[ny,nx]!=0:\n",
    "                        visited[ny,nx]=True\n",
    "                        stack.append((ny,nx))\n",
    "\n",
    "            mask = np.zeros((y2-y1+1, x2-x1+1), bool)\n",
    "            for py, px in pixels:\n",
    "                mask[py-y1, px-x1] = True\n",
    "\n",
    "            dom_color = max(color_counts, key=color_counts.get)\n",
    "            centroid = (\n",
    "                float(np.mean([p[0] for p in pixels])),\n",
    "                float(np.mean([p[1] for p in pixels]))\n",
    "            )\n",
    "\n",
    "            # rotation/mirror signatures for later matching\n",
    "            sig_rot90 = np.rot90(mask)\n",
    "            sig_mirror = np.fliplr(mask)\n",
    "\n",
    "            objects.append({\n",
    "                "id": obj_id,\n",
    "                "bbox": (y1, x1, y2+1, x2+1),\n",
    "                "mask": mask,\n",
    "                "colors": color_counts,\n",
    "                "dominant": dom_color,\n",
    "                "centroid": centroid,\n",
    "                "sig_rot90": sig_rot90,\n",
    "                "sig_mirror": sig_mirror,\n",
    "            })\n",
    "            obj_id += 1\n",
    "\n",
    "    return objects\n",
    "# write to /kaggle/working/arc_solver/step1_objects.py",
    "open('/kaggle/working/arc_solver/step1_objects.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step1_objects.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "# ============================================================\n",
    "# step20_meta_summary.py — Meta Promotion Summary Tracker\n",
    "# Records threshold, promotion count, and replay size over runs\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "WORK = Path("/data/data/com.termux/files/home/arc_solver")\n",
    "SUMMARY_PATH = WORK / "meta_summary.json"\n",
    "REPLAY_PATH = WORK / "meta_replay.json"\n",
    "\n",
    "def _load_json(path: Path):\n",
    "    if path.exists():\n",
    "        try:\n",
    "            with open(path) as f:\n",
    "                return json.load(f)\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def _save_json(path: Path, data):\n",
    "    with open(path, "w") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "def record_summary(threshold: float, promoted: int):\n",
    "    replay = _load_json(REPLAY_PATH)\n",
    "    entry = {\n",
    "        "timestamp": datetime.utcnow().isoformat(),\n",
    "        "threshold": round(threshold, 3),\n",
    "        "promoted": promoted,\n",
    "        "replay_size": len(replay) if isinstance(replay, list) else 0,\n",
    "    }\n",
    "\n",
    "    if SUMMARY_PATH.exists():\n",
    "        data = _load_json(SUMMARY_PATH)\n",
    "        if not isinstance(data, list):\n",
    "            data = []\n",
    "        data.append(entry)\n",
    "    else:\n",
    "        data = [entry]\n",
    "\n",
    "    _save_json(SUMMARY_PATH, data)\n",
    "    print(f"[SUMMARY] Logged promotion summary → {SUMMARY_PATH}")\n",
    "# write to /kaggle/working/arc_solver/step20_meta_summary.py",
    "open('/kaggle/working/arc_solver/step20_meta_summary.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step20_meta_summary.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "import json, math, hashlib\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Tuple\n",
    "\n",
    "WORK = Path("/data/data/com.termux/files/home/arc_solver")\n",
    "META_PATH = WORK / "meta_cache.json"\n",
    "CACHE_PATH = WORK / "cache.json"\n",
    "\n",
    "# ---------------- IO ----------------\n",
    "\n",
    "def _load_json(path: Path):\n",
    "    try:\n",
    "        if path.exists():\n",
    "            with open(path) as f:\n",
    "                return json.load(f)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # default container types\n",
    "    return {} if path.suffix == ".json" else {}\n",
    "\n",
    "def _save_json(path: Path, data):\n",
    "    with open(path, "w") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "# ---------------- signatures & distances ----------------\n",
    "\n",
    "def _norm_cmap(cmap: Dict[Any, Any]) -> Dict[int, int]:\n",
    "    """Coerce to {int:int}, drop invalid keys."""\n",
    "    out = {}\n",
    "    for k, v in (cmap or {}).items():\n",
    "        try:\n",
    "            out[int(k)] = int(v)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return out\n",
    "\n",
    "def _pairs(cmap: Dict[int, int]) -> List[Tuple[int, int]]:\n",
    "    """Sorted (k->v) pairs for stable hashing/compare."""\n",
    "    return sorted((int(k), int(v)) for k, v in cmap.items())\n",
    "\n",
    "def _sig_str(cmap: Dict[int,int]) -> str:\n",
    "    """Stable signature string for a color map."""\n",
    "    p = _pairs(cmap)\n",
    "    raw = ";".join(f"{k}->{v}" for k,v in p)\n",
    "    # include size to avoid collisions of different sizes with same prefix\n",
    "    raw = f"n={len(p)}|" + raw\n",
    "    return hashlib.sha1(raw.encode("utf-8")).hexdigest()\n",
    "\n",
    "def _sig_distance(a: Dict[int,int], b: Dict[int,int]) -> float:\n",
    "    """\n",
    "    Distance in [0,1] based on Jaccard of mapping pairs.\n",
    "      dist = 1 - |A∩B| / |A∪B|\n",
    "    """\n",
    "    A = set(_pairs(a))\n",
    "    B = set(_pairs(b))\n",
    "    if not A and not B: \n",
    "        return 0.0\n",
    "    jacc = len(A& B) / float(len(A | B))\n",
    "    return 1.0 - jacc\n",
    "\n",
    "# ---------------- capacity heuristic ----------------\n",
    "\n",
    "def _auto_cap(n: int) -> int:\n",
    "    """\n",
    "    Sublinear growth: ≤8: n, else ~4*sqrt(n) clamped to [8,64]\n",
    "    """\n",
    "    if n <= 8:\n",
    "        return n\n",
    "    return max(8, min(64, int(math.ceil(n ** 0.5) * 4)))\n",
    "\n",
    "# ---------------- main rehearse ----------------\n",
    "\n",
    "def rehearse_meta(cap: int | str = "auto", diversity: float = 0.33, min_sig_dist: float = 0.35) -> int:\n",
    "    """\n",
    "    Load top meta rules into solver cache with capacity & signature diversity.\n",
    "\n",
    "    Args:\n",
    "      cap: "auto" or integer count of rules to load.\n",
    "      diversity: fraction of K we try to make signature-distinct (ceil(diversity*K)).\n",
    "      min_sig_dist: minimum pairwise signature distance between selected rules.\n",
    "    Returns:\n",
    "      Number of rules injected into cache.\n",
    "    """\n",
    "    meta = _load_json(META_PATH)\n",
    "    cache = _load_json(CACHE_PATH)\n",
    "\n",
    "    # Collect candidates\n",
    "    items: List[Dict[str, Any]] = []\n",
    "    if isinstance(meta, dict):\n",
    "        for rid, rule in meta.items():\n",
    "            if not isinstance(rule, dict):\n",
    "                continue\n",
    "            rtype = str(rule.get("type", ""))\n",
    "            if not rtype.endswith("_meta"):\n",
    "                continue\n",
    "            cmap = _norm_cmap(rule.get("color_map", {}))\n",
    "            conf = float(rule.get("confidence", 0.0))\n",
    "            items.append({\n",
    "                "rid": rid,\n",
    "                "type": rtype,               # often "color_map_meta"\n",
    "                "color_map": cmap,\n",
    "                "confidence": conf,\n",
    "                "sig": _sig_str(cmap),\n",
    "            })\n",
    "\n",
    "    if not items:\n",
    "        print("[REHEARSE] Meta cache contained no *meta* rules.")\n",
    "        return 0\n",
    "\n",
    "    # Sort by confidence desc, dedupe by signature first\n",
    "    items.sort(key=lambda x: x["confidence"], reverse=True)\n",
    "    seen_sig = set()\n",
    "    uniq: List[Dict[str,Any]] = []\n",
    "    for it in items:\n",
    "        if it["sig"] in seen_sig:\n",
    "            continue\n",
    "        seen_sig.add(it["sig"])\n",
    "        uniq.append(it)\n",
    "    items = uniq\n",
    "\n",
    "    N = len(items)\n",
    "    if N == 0:\n",
    "        print("[REHEARSE] All meta rules were duplicates by signature.")\n",
    "        return 0\n",
    "\n",
    "    # Determine K\n",
    "    if cap == "auto":\n",
    "        K = _auto_cap(N)\n",
    "    elif isinstance(cap, int) and cap > 0:\n",
    "        K = cap\n",
    "    else:\n",
    "        K = N\n",
    "    K = max(1, min(N, K))\n",
    "\n",
    "    # Target number of signature-distinct picks\n",
    "    target_distinct = max(1, min(K, int(math.ceil(diversity * K))))\n",
    "\n",
    "    # Greedy selection with signature distance constraint\n",
    "    selected: List[Dict[str,Any]] = []\n",
    "    sigs: List[str] = []\n",
    "\n",
    "    # Adaptive relaxation if we can't fill K\n",
    "    relax = min_sig_dist\n",
    "    idx = 0\n",
    "    while len(selected) < K and idx < N:\n",
    "        cand = items[idx]\n",
    "        ok = True\n",
    "        for s in selected:\n",
    "            d = _sig_distance(cand["color_map"], s["color_map"])\n",
    "            if d < relax:\n",
    "                ok = False\n",
    "                break\n",
    "        if ok:\n",
    "            selected.append(cand)\n",
    "            sigs.append(cand["sig"])\n",
    "        idx += 1\n",
    "\n",
    "        # If we ran through list and still underfilled: relax and restart pass\n",
    "        if idx == N and len(selected) < K:\n",
    "            # Relax only if we still haven't reached target distinct\n",
    "            if len({x["sig"] for x in selected}) < target_distinct and relax > 0.05:\n",
    "                relax = max(0.05, round(relax * 0.85, 3))  # relax by 15%\n",
    "                idx = 0\n",
    "                # keep current selected but allow closer future picks\n",
    "            else:\n",
    "                break  # accept fewer than K if constraints tight\n",
    "\n",
    "    # If still short, top up ignoring distance (but keep unique signatures first)\n",
    "    if len(selected) < K:\n",
    "        needed = K - len(selected)\n",
    "        pool = [it for it in items if it["sig"] not in {x["sig"] for x in selected}]\n",
    "        selected.extend(pool[:needed])\n",
    "\n",
    "    # Purge old rehearse_* entries\n",
    "    if not isinstance(cache, dict):\n",
    "        cache = {}\n",
    "    else:\n",
    "        for k in list(cache.keys()):\n",
    "            if isinstance(k, str) and k.startswith("rehearse_"):\n",
    "                del cache[k]\n",
    "\n",
    "    # Inject selected rules\n",
    "    for i, r in enumerate(selected, 1):\n",
    "        tid = f"rehearse_{r['rid']}_{i}"\n",
    "        cache[tid] = {\n",
    "            "type": r["type"],                 # e.g., "color_map_meta"\n",
    "            "color_map": r["color_map"],\n",
    "            "confidence": r["confidence"],\n",
    "            "sig": r["sig"],\n",
    "        }\n",
    "\n",
    "    _save_json(CACHE_PATH, cache)\n",
    "\n",
    "    # Reporting\n",
    "    # logical "types" (likely 1) + signature diversity (what we care about)\n",
    "    type_count = len({r["type"] for r in selected})\n",
    "    sig_count = len({r["sig"] for r in selected})\n",
    "    top3 = ", ".join(f"{r['rid']}:{r['confidence']:.3f}" for r in selected[:3])\n",
    "    print(f"[REHEARSE] Loaded {len(selected)}/{N} meta rules → cache "\n",
    "          f"(types={type_count}, sigs={sig_count}, min_sig_dist={min_sig_dist}, relax_final={relax}, top3: {top3})")\n",
    "    return len(selected)\n",
    "\n",
    "if __name__ == "__main__":\n",
    "    rehearse_meta()\n",
    "# write to /kaggle/working/arc_solver/step21_meta_rehearse.py",
    "open('/kaggle/working/arc_solver/step21_meta_rehearse.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step21_meta_rehearse.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "import json, math, hashlib\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from typing import Dict, Any, List, Tuple\n",
    "\n",
    "WORK = Path("/data/data/com.termux/files/home/arc_solver")\n",
    "META_PATH = WORK / "meta_cache.json"\n",
    "REPLAY_PATH = WORK / "replay.json"\n",
    "\n",
    "# ---------- IO ----------\n",
    "def _load_json(path: Path):\n",
    "    try:\n",
    "        if path.exists():\n",
    "            with open(path) as f:\n",
    "                return json.load(f)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return {} if path.suffix == ".json" else {}\n",
    "\n",
    "def _save_json(path: Path, data):\n",
    "    with open(path, "w") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _norm_cmap(cmap: Dict[Any, Any]) -> Dict[int,int]:\n",
    "    out = {}\n",
    "    for k, v in (cmap or {}).items():\n",
    "        try:\n",
    "            out[int(k)] = int(v)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return out\n",
    "\n",
    "def _pairs(cmap: Dict[int,int]) -> List[Tuple[int,int]]:\n",
    "    return sorted((int(k), int(v)) for k, v in cmap.items())\n",
    "\n",
    "def _sig_str(cmap: Dict[int,int]) -> str:\n",
    "    p = _pairs(cmap)\n",
    "    raw = "n=%d|" % len(p) + ";".join(f"{k}->{v}" for k, v in p)\n",
    "    return hashlib.sha1(raw.encode("utf-8")).hexdigest()\n",
    "\n",
    "def _is_bijection(cmap: Dict[int,int]) -> bool:\n",
    "    vals = list(cmap.values())\n",
    "    return len(set(vals)) == len(vals)\n",
    "\n",
    "def _invert(cmap: Dict[int,int]) -> Dict[int,int]:\n",
    "    if not _is_bijection(cmap):\n",
    "        return {}\n",
    "    return {int(v): int(k) for k, v in cmap.items()}\n",
    "\n",
    "def _shift(cmap: Dict[int,int], s: int) -> Dict[int,int]:\n",
    "    # shift outputs mod 10 (ARC colors 0..9)\n",
    "    return {k: (v + s) % 10 for k, v in cmap.items()}\n",
    "\n",
    "def _prune_least_supported(cmap: Dict[int,int], support: Dict[Tuple[int,int], float]) -> Dict[int,int]:\n",
    "    if len(cmap) <= 1:\n",
    "        return {}\n",
    "    # rank by support (low first), drop one weakest pair\n",
    "    items = list(cmap.items())\n",
    "    items.sort(key=lambda kv: support.get((int(kv[0]), int(kv[1])), 0.0))\n",
    "    drop_k, _ = items[0]\n",
    "    out = dict(cmap)\n",
    "    out.pop(drop_k, None)\n",
    "    return out\n",
    "\n",
    "# ---------- core ----------\n",
    "def diversify_meta(target: int = 24, min_new: int = 8, max_shifts: int = 2) -> int:\n",
    "    """\n",
    "    Synthesize distinct color_map_meta entries from replay+meta to raise signature diversity.\n",
    "\n",
    "    Args:\n",
    "      target: soft target of total meta entries desired after diversification.\n",
    "      min_new: minimum number of *new* signatures to add per call (if available).\n",
    "      max_shifts: how many output shifts to try per map.\n",
    "    Returns:\n",
    "      Number of new meta entries added.\n",
    "    """\n",
    "    meta = _load_json(META_PATH)\n",
    "    if not isinstance(meta, dict):\n",
    "        meta = {}\n",
    "\n",
    "    replay = _load_json(REPLAY_PATH)\n",
    "    if not isinstance(replay, list):\n",
    "        replay = []\n",
    "\n",
    "    # gather base maps (existing meta + replay)\n",
    "    base_maps: List[Dict[str, Any]] = []\n",
    "\n",
    "    # from meta\n",
    "    for rid, rule in (meta or {}).items():\n",
    "        if isinstance(rule, dict) and str(rule.get("type","")).endswith("_meta"):\n",
    "            cmap = _norm_cmap(rule.get("color_map", {}))\n",
    "            if cmap:\n",
    "                base_maps.append({"rid": rid, "conf": float(rule.get("confidence", 0.7)), "cmap": cmap})\n",
    "\n",
    "    # from replay (as candidates)\n",
    "    for i, entry in enumerate(replay):\n",
    "        cmap = _norm_cmap(entry.get("color_map", {}))\n",
    "        if cmap:\n",
    "            base_maps.append({"rid": f"replay_{i}", "conf": float(entry.get("confidence", 0.0)), "cmap": cmap})\n",
    "\n",
    "    if not base_maps:\n",
    "        print("[DIVERSIFY] No base maps available.")\n",
    "        return 0\n",
    "\n",
    "    # compute support for pairs from replay (confidence-weighted)\n",
    "    support = Counter()\n",
    "    for entry in replay:\n",
    "        conf = float(entry.get("confidence", 0.0))\n",
    "        weight = 1.0 + max(0.0, conf)  # ≥1\n",
    "        cmap = _norm_cmap(entry.get("color_map", {}))\n",
    "        for k, v in cmap.items():\n",
    "            support[(int(k), int(v))] += weight\n",
    "\n",
    "    # set of existing signatures to avoid dup\n",
    "    existing_sigs = set()\n",
    "    for rule in meta.values():\n",
    "        if isinstance(rule, dict) and "color_map" in rule:\n",
    "            existing_sigs.add(_sig_str(_norm_cmap(rule["color_map"])))\n",
    "\n",
    "    # candidate generation\n",
    "    generated: List[Dict[str, Any]] = []\n",
    "    for bm in base_maps:\n",
    "        base = bm["cmap"]\n",
    "        sig_base = _sig_str(base)\n",
    "        # 1) inverse if bijection\n",
    "        inv = _invert(base)\n",
    "        if inv:\n",
    "            sig = _sig_str(inv)\n",
    "            if sig not in existing_sigs:\n",
    "                generated.append({"cmap": inv, "conf": bm["conf"] * 0.98, "src": f"{bm['rid']}:invert"})\n",
    "\n",
    "        # 2) shifts\n",
    "        for s in range(1, max_shifts + 1):\n",
    "            sh = _shift(base, s)\n",
    "            sig = _sig_str(sh)\n",
    "            if sig not in existing_sigs:\n",
    "                generated.append({"cmap": sh, "conf": bm["conf"] * (0.97 - 0.01*(s-1)), "src": f"{bm['rid']}:shift{s}"})\n",
    "\n",
    "        # 3) prune weakest pair (if any support known)\n",
    "        pr = _prune_least_supported(base, support)\n",
    "        if pr:\n",
    "            sig = _sig_str(pr)\n",
    "            if sig not in existing_sigs:\n",
    "                generated.append({"cmap": pr, "conf": max(0.6, bm["conf"] * 0.95), "src": f"{bm['rid']}:prune1"})\n",
    "\n",
    "    if not generated:\n",
    "        print("[DIVERSIFY] No new variants synthesized.")\n",
    "        return 0\n",
    "\n",
    "    # rank by confidence (variants carry slightly decayed conf)\n",
    "    generated.sort(key=lambda x: x["conf"], reverse=True)\n",
    "\n",
    "    # add until we hit min_new or target total size, skipping duplicate signatures\n",
    "    added = 0\n",
    "    for cand in generated:\n",
    "        if len(meta) >= max(target, len(meta) + min_new):  # safety\n",
    "            break\n",
    "        sig = _sig_str(cand["cmap"])\n",
    "        if sig in existing_sigs:\n",
    "            continue\n",
    "        rid = f"meta_div_{len(meta)+1}"\n",
    "        meta[rid] = {\n",
    "            "type": "color_map_meta",\n",
    "            "color_map": cand["cmap"],\n",
    "            "confidence": round(float(cand["conf"]), 3),\n",
    "            "source": f"diversify({cand['src']})",\n",
    "        }\n",
    "        existing_sigs.add(sig)\n",
    "        added += 1\n",
    "        if added >= min_new:\n",
    "            # we reached minimum; continue a bit if total < target\n",
    "            if len(meta) >= target:\n",
    "                break\n",
    "\n",
    "    _save_json(META_PATH, meta)\n",
    "    print(f"[DIVERSIFY] Added {added} meta variants → {META_PATH} (now total={len(meta)})")\n",
    "    return added\n",
    "\n",
    "if __name__ == "__main__":\n",
    "    diversify_meta()\n",
    "# write to /kaggle/working/arc_solver/step22_meta_diversify.py",
    "open('/kaggle/working/arc_solver/step22_meta_diversify.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step22_meta_diversify.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any, Callable\n",
    "\n",
    "from arc_solver.step5_transforms import rotate90, flip_x, flip_y\n",
    "\n",
    "WORK = Path("/data/data/com.termux/files/home/arc_solver")\n",
    "CACHE_PATH  = WORK / "cache.json"\n",
    "META_PATH   = WORK / "meta_cache.json"\n",
    "REPLAY_PATH = WORK / "replay.json"\n",
    "\n",
    "# ---------------- IO ----------------\n",
    "def _load_json(path: Path):\n",
    "    try:\n",
    "        if path.exists():\n",
    "            with open(path) as f:\n",
    "                return json.load(f)\n",
    "    except Exception:\n",
    "        pass\n",
    "    if path == CACHE_PATH:\n",
    "        return {}\n",
    "    if path == META_PATH:\n",
    "        return {}\n",
    "    if path == REPLAY_PATH:\n",
    "        return []\n",
    "    return {}\n",
    "\n",
    "# ---------------- color-map utils ----------------\n",
    "def _norm_cmap(cmap: Dict[Any, Any]) -> Dict[int, int]:\n",
    "    out = {}\n",
    "    for k, v in (cmap or {}).items():\n",
    "        try:\n",
    "            out[int(k)] = int(v)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return out\n",
    "\n",
    "def _cmap_sig(cmap: Dict[int,int]) -> str:\n",
    "    items = sorted((int(k), int(v)) for k, v in (cmap or {}).items())\n",
    "    return ";".join(f"{k}->{v}" for k, v in items)\n",
    "\n",
    "def _apply_cmap(grid: np.ndarray, cmap: Dict[int,int]) -> np.ndarray:\n",
    "    lut = np.arange(10, dtype=np.int16)\n",
    "    for k, v in cmap.items():\n",
    "        if 0 <= k <= 9 and 0 <= v <= 9:\n",
    "            lut[k] = v\n",
    "    return lut[grid]\n",
    "\n",
    "# ---------------- transforms as (forward, inverse) ----------------\n",
    "def _transforms() -> List[Tuple[str, Callable[[np.ndarray], np.ndarray], Callable[[np.ndarray], np.ndarray]]]:\n",
    "    # Our rotate90(g, k) is clockwise by k*90 (wrapper uses np.rot90 with negative k).\n",
    "    return [\n",
    "        ("id",      lambda g: g,                 lambda g: g),\n",
    "        ("rot90",   lambda g: rotate90(g, 1),   lambda g: rotate90(g, 3)),\n",
    "        ("rot180",  lambda g: rotate90(g, 2),   lambda g: rotate90(g, 2)),\n",
    "        ("rot270",  lambda g: rotate90(g, 3),   lambda g: rotate90(g, 1)),\n",
    "        ("flip_x",  lambda g: flip_x(g),        lambda g: flip_x(g)),  # self-inverse\n",
    "        ("flip_y",  lambda g: flip_y(g),        lambda g: flip_y(g)),  # self-inverse\n",
    "    ]\n",
    "\n",
    "# ---------------- candidate gathering ----------------\n",
    "def collect_candidate_maps(task_id: str) -> List[Dict[str, Any]]:\n",
    "    cands: List[Dict[str, Any]] = []\n",
    "    cache  = _load_json(CACHE_PATH)\n",
    "    meta   = _load_json(META_PATH)\n",
    "    replay = _load_json(REPLAY_PATH)\n",
    "\n",
    "    # task-specific cached rule\n",
    "    if isinstance(cache, dict) and task_id in cache:\n",
    "        rule = cache[task_id]\n",
    "        if isinstance(rule, dict) and "color_map" in rule:\n",
    "            cands.append({\n",
    "                "type": rule.get("type", "cache"),\n",
    "                "color_map": _norm_cmap(rule.get("color_map", {})),\n",
    "                "confidence": float(rule.get("confidence", 0.6)),\n",
    "                "source": f"cache:{task_id[:8]}",\n",
    "            })\n",
    "\n",
    "    # rehearse_* injected meta rules\n",
    "    if isinstance(cache, dict):\n",
    "        for k, rule in cache.items():\n",
    "            if isinstance(k, str) and k.startswith("rehearse_") and isinstance(rule, dict):\n",
    "                cm = _norm_cmap(rule.get("color_map", {}))\n",
    "                if cm:\n",
    "                    cands.append({\n",
    "                        "type": rule.get("type", "meta"),\n",
    "                        "color_map": cm,\n",
    "                        "confidence": float(rule.get("confidence", 0.7)),\n",
    "                        "source": f"cache:{k}",\n",
    "                    })\n",
    "\n",
    "    # meta rules\n",
    "    if isinstance(meta, dict):\n",
    "        for rid, rule in meta.items():\n",
    "            if isinstance(rule, dict) and str(rule.get("type","")).endswith("_meta"):\n",
    "                cm = _norm_cmap(rule.get("color_map", {}))\n",
    "                if cm:\n",
    "                    cands.append({\n",
    "                        "type": rule.get("type", "meta"),\n",
    "                        "color_map": cm,\n",
    "                        "confidence": float(rule.get("confidence", 0.7)),\n",
    "                        "source": f"meta:{rid}",\n",
    "                    })\n",
    "\n",
    "    # replay memory\n",
    "    if isinstance(replay, list):\n",
    "        for i, entry in enumerate(replay):\n",
    "            cm = _norm_cmap(entry.get("color_map", {}))\n",
    "            if cm:\n",
    "                cands.append({\n",
    "                    "type": entry.get("rule_type", "replay"),\n",
    "                    "color_map": cm,\n",
    "                    "confidence": float(entry.get("confidence", 0.6)),\n",
    "                    "source": f"replay:{i}",\n",
    "                })\n",
    "\n",
    "    # identity fallback\n",
    "    ident = {i: i for i in range(10)}\n",
    "    cands.append({"type":"identity","color_map":ident,"confidence":0.5,"source":"fallback:identity"})\n",
    "\n",
    "    # dedupe by signature, keep highest conf\n",
    "    best_by_sig: Dict[str, Dict[str, Any]] = {}\n",
    "    for c in cands:\n",
    "        sig = _cmap_sig(c["color_map"])\n",
    "        if sig not in best_by_sig or c["confidence"] > best_by_sig[sig]["confidence"]:\n",
    "            best_by_sig[sig] = c\n",
    "    return list(best_by_sig.values())\n",
    "\n",
    "# ---------------- scoring (supervised on train pairs) ----------------\n",
    "def _score_variant_on_pairs(pairs: List[Dict[str, Any]],\n",
    "                            cmap: Dict[int,int],\n",
    "                            tname: str,\n",
    "                            fwd, inv) -> float:\n",
    "    if not pairs:\n",
    "        return 0.5\n",
    "    scores = []\n",
    "    for p in pairs:\n",
    "        inp = np.array(p["input"], dtype=np.int16)\n",
    "        out = np.array(p["output"], dtype=np.int16)\n",
    "        # Align with ground truth: inv(fwd(inp) → cmap → pred_t) should match out\n",
    "        x_t   = fwd(inp)\n",
    "        y_t   = _apply_cmap(x_t, cmap)\n",
    "        pred  = inv(y_t)\n",
    "        if pred.shape != out.shape:\n",
    "            # guardrail: mismatched shapes get a low score rather than crash\n",
    "            scores.append(0.0)\n",
    "        else:\n",
    "            acc = float(np.mean(pred == out))\n",
    "            scores.append(acc)\n",
    "    return float(np.mean(scores)) if scores else 0.5\n",
    "\n",
    "# ---------------- public API ----------------\n",
    "def ensemble_predict(task: Dict[str, Any], topk: int = 2) -> Tuple[List[List[List[int]]], float]:\n",
    "    task_id = task.get("id", "unknown")\n",
    "    train_pairs = task.get("train", [])\n",
    "    tests = task.get("test", [])\n",
    "\n",
    "    cands = collect_candidate_maps(task_id)\n",
    "    if not cands:\n",
    "        return [], 0.0\n",
    "\n",
    "    # Build (cmap × transform) variants and score on training pairs\n",
    "    variants: List[Tuple[float, Dict[str, Any], str, Callable, Callable]] = []\n",
    "    for c in cands:\n",
    "        cm = c["color_map"]\n",
    "        for tname, fwd, inv in _transforms():\n",
    "            s = _score_variant_on_pairs(train_pairs, cm, tname, fwd, inv)\n",
    "            variants.append((s, c, tname, fwd, inv))\n",
    "\n",
    "    # rank by supervised score\n",
    "    variants.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # take the best K variants\n",
    "    top = variants[:max(1, topk)]\n",
    "    mean_conf = float(np.mean([s for s, *_ in top])) if top else 0.0\n",
    "    mean_conf = round(mean_conf, 3)\n",
    "\n",
    "    # predict tests using the same fwd→cmap→inv pipeline\n",
    "    preds_all: List[List[List[int]]] = []\n",
    "    for sample in tests:\n",
    "        inp = np.array(sample["input"], dtype=np.int16)\n",
    "        outs: List[List[int]] = []\n",
    "        for s, c, tname, fwd, inv in top:\n",
    "            x_t   = fwd(inp)\n",
    "            y_t   = _apply_cmap(x_t, c["color_map"])\n",
    "            pred  = inv(y_t)\n",
    "            outs.append(pred.tolist())\n",
    "        while len(outs) < 2:\n",
    "            outs.append(outs[0])\n",
    "        preds_all.append(outs)\n",
    "\n",
    "    return preds_all, mean_conf\n",
    "\n",
    "if __name__ == "__main__":\n",
    "    pass\n",
    "# write to /kaggle/working/arc_solver/step23_meta_ensemble.py",
    "open('/kaggle/working/arc_solver/step23_meta_ensemble.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step23_meta_ensemble.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "import json\n",
    "from pathlib import Path\n",
    "from arc_solver.config import WORK\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "MERGED_PATH = WORK / "merged_dataset.json"\n",
    "\n",
    "def _is_rect_grid(g: Any) -> bool:\n",
    "    if not isinstance(g, list) or not g:\n",
    "        return False\n",
    "    if not all(isinstance(row, list) and row for row in g):\n",
    "        return False\n",
    "    w = len(g[0])\n",
    "    return all(len(r) == w for r in g)\n",
    "\n",
    "def _vals_ok(g: List[List[int]]) -> bool:\n",
    "    try:\n",
    "        for r in g:\n",
    "            for v in r:\n",
    "                if not isinstance(v, int) or v < 0 or v > 9:\n",
    "                    return False\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _load_merged() -> Dict[str, Any]:\n",
    "    with open(MERGED_PATH) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def validate(results: Dict[str, Any], merged: Dict[str, Any]) -> List[str]:\n",
    "    issues: List[str] = []\n",
    "    tasks = merged if isinstance(merged, list) else merged.get("tasks", merged)\n",
    "\n",
    "    # tasks could be list or dict keyed by id; normalize into list of items with id+test\n",
    "    norm = []\n",
    "    if isinstance(tasks, list):\n",
    "        norm = tasks\n",
    "    elif isinstance(tasks, dict):\n",
    "        for v in tasks.values():\n",
    "            norm.append(v)\n",
    "\n",
    "    for t in norm:\n",
    "        tid = t.get("id", "unknown")\n",
    "        tests = t.get("test", [])\n",
    "        # Must exist\n",
    "        if tid not in results:\n",
    "            issues.append(f"Missing key for task {tid}")\n",
    "            continue\n",
    "        pred_tests = results[tid]\n",
    "        # Must match #tests\n",
    "        if not isinstance(pred_tests, list) or len(pred_tests) != len(tests):\n",
    "            issues.append(f"Task {tid} has {len(pred_tests) if isinstance(pred_tests, list) else 'non-list'} preds "\n",
    "                          f"but dataset has {len(tests)} tests")\n",
    "            continue\n",
    "        # Each test: exactly 2 attempts; each attempt rectangular 0..9\n",
    "        for i, outs in enumerate(pred_tests):\n",
    "            if not isinstance(outs, list):\n",
    "                issues.append(f"{tid}[{i}] predictions not a list")\n",
    "                continue\n",
    "            if len(outs) != 2:\n",
    "                issues.append(f"{tid}[{i}] has {len(outs)} attempts (expected 2)")\n",
    "                continue\n",
    "            for a_idx, grid in enumerate(outs):\n",
    "                if not _is_rect_grid(grid):\n",
    "                    issues.append(f"{tid}[{i}][{a_idx}] not a rectangular 2D list")\n",
    "                    continue\n",
    "                if not _vals_ok(grid):\n",
    "                    issues.append(f"{tid}[{i}][{a_idx}] contains non-int or out-of-range values")\n",
    "    return issues\n",
    "\n",
    "def validate_and_fix(results: Dict[str, Any], merged: Dict[str, Any]) -> Tuple[Dict[str, Any], List[str]]:\n",
    "    """Best-effort fixer: ensures 2 attempts per test by duplicating first; drops invalid items."""\n",
    "    issues = []\n",
    "    tasks = merged if isinstance(merged, list) else merged.get("tasks", merged)\n",
    "\n",
    "    # Normalize task list\n",
    "    norm = []\n",
    "    if isinstance(tasks, list):\n",
    "        norm = tasks\n",
    "    elif isinstance(tasks, dict):\n",
    "        for v in tasks.values():\n",
    "            norm.append(v)\n",
    "\n",
    "    fixed = dict(results)\n",
    "    for t in norm:\n",
    "        tid = t.get("id", "unknown")\n",
    "        tests = t.get("test", [])\n",
    "        if tid not in fixed:\n",
    "            # fabricate empty two-attempt grids mirroring input shapes (fallback)\n",
    "            fallback = []\n",
    "            for s in tests:\n",
    "                h = len(s["input"])\n",
    "                w = len(s["input"][0]) if h else 0\n",
    "                g = [[0]*w for _ in range(h)]\n",
    "                fallback.append([g, g])\n",
    "            fixed[tid] = fallback\n",
    "            issues.append(f"Injected fallback for missing task {tid}")\n",
    "            continue\n",
    "\n",
    "        outs = fixed[tid]\n",
    "        if not isinstance(outs, list) or len(outs) != len(tests):\n",
    "            # try to coerce: if single test provided, replicate to match count\n",
    "            if isinstance(outs, list) and len(outs) == 1 and len(tests) > 1:\n",
    "                fixed[tid] = outs * len(tests)\n",
    "                issues.append(f"Replicated single test preds for {tid} to {len(tests)}")\n",
    "            else:\n",
    "                # truncate or pad with duplicate of first\n",
    "                if isinstance(outs, list):\n",
    "                    if len(outs) > len(tests):\n",
    "                        fixed[tid] = outs[:len(tests)]\n",
    "                        issues.append(f"Truncated extra test preds for {tid}")\n",
    "                    else:\n",
    "                        while len(outs) < len(tests):\n",
    "                            outs.append(outs[0] if outs else [[[]],[[]]])\n",
    "                        issues.append(f"Padded missing test preds for {tid}")\n",
    "                else:\n",
    "                    # make fully new\n",
    "                    fallback = []\n",
    "                    for s in tests:\n",
    "                        h = len(s["input"])\n",
    "                        w = len(s["input"][0]) if h else 0\n",
    "                        g = [[0]*w for _ in range(h)]\n",
    "                        fallback.append([g, g])\n",
    "                    fixed[tid] = fallback\n",
    "                    issues.append(f"Replaced non-list preds for {tid}")\n",
    "\n",
    "        # ensure exactly two attempts per test\n",
    "        new_tests = []\n",
    "        for outs in fixed[tid]:\n",
    "            if not isinstance(outs, list) or not outs:\n",
    "                new_tests.append([[[0]], [[0]]])\n",
    "                issues.append("Replaced invalid attempt list with 1x1 zeros")\n",
    "                continue\n",
    "            outs2 = list(outs)\n",
    "            if len(outs2) == 1:\n",
    "                outs2.append(outs2[0])\n",
    "                issues.append("Duplicated single attempt to two attempts")\n",
    "            elif len(outs2) > 2:\n",
    "                outs2 = outs2[:2]\n",
    "                issues.append("Truncated to two attempts")\n",
    "            # final sanity: rectangular 0..9; if not, coerce to zeros with same shape as first\n",
    "            def ok(g):\n",
    "                return isinstance(g, list) and _is_rect_grid(g) and _vals_ok(g)\n",
    "            if not ok(outs2[0]):\n",
    "                outs2[0] = [[0]]\n",
    "                issues.append("Coerced bad attempt[0] to 1x1 zero")\n",
    "            if not ok(outs2[1]):\n",
    "                # try use shape of attempt[0]\n",
    "                h = len(outs2[0]); w = len(outs2[0][0]) if h else 1\n",
    "                outs2[1] = [[0]*w for _ in range(h if h else 1)]\n",
    "                issues.append("Coerced bad attempt[1] to zeros")\n",
    "            new_tests.append(outs2)\n",
    "        fixed[tid] = new_tests\n",
    "\n",
    "    # final report\n",
    "    problems = validate(fixed, merged)\n",
    "    return fixed, issues + problems\n",
    "\n",
    "if __name__ == "__main__":\n",
    "    merged = _load_merged()\n",
    "    # For CLI quick-check of the saved submission.json\n",
    "    sub_path = WORK / "submission.json"\n",
    "    if sub_path.exists():\n",
    "        data = json.loads(sub_path.read_text())\n",
    "        problems = validate(data, merged)\n",
    "        if problems:\n",
    "            print("[SUBMIT-CHECK] Problems:")\n",
    "            for p in problems:\n",
    "                print(" -", p)\n",
    "        else:\n",
    "            print("[SUBMIT-CHECK] OK")\n",
    "    else:\n",
    "        print("[SUBMIT-CHECK] No submission.json present")\n",
    "# write to /kaggle/working/arc_solver/step24_check_submission.py",
    "open('/kaggle/working/arc_solver/step24_check_submission.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step24_check_submission.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# arc_solver/step2_compare.py\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "def compare_objects(in_objs: List[Dict], out_objs: List[Dict]) -> Dict[str, any]:\n",
    "    """\n",
    "    Compare input and output object lists.\n",
    "    Detects simple pattern types:\n",
    "      - color_map: same shapes, colors changed\n",
    "      - translation: same shapes and colors, shifted positions\n",
    "    Returns summary dictionary.\n",
    "    """\n",
    "    result = {"type": "unknown", "color_map": {}, "shift": (0, 0)}\n",
    "\n",
    "    if len(in_objs) != len(out_objs):\n",
    "        return result\n",
    "\n",
    "    # try color remap\n",
    "    color_map = {}\n",
    "    same_shape_count = 0\n",
    "    for i_obj, o_obj in zip(in_objs, out_objs):\n",
    "        if i_obj["mask"].shape == o_obj["mask"].shape:\n",
    "            same_shape_count += 1\n",
    "            in_main = max(i_obj["colors"], key=i_obj["colors"].get)\n",
    "            out_main = max(o_obj["colors"], key=o_obj["colors"].get)\n",
    "            color_map[in_main] = out_main\n",
    "\n",
    "    if same_shape_count == len(in_objs):\n",
    "        result["type"] = "color_map"\n",
    "        result["color_map"] = color_map\n",
    "        return result\n",
    "\n",
    "    # try translation\n",
    "    shifts = []\n",
    "    for i_obj, o_obj in zip(in_objs, out_objs):\n",
    "        y1_i, x1_i, *_ = i_obj["bbox"]\n",
    "        y1_o, x1_o, *_ = o_obj["bbox"]\n",
    "        shifts.append((y1_o - y1_i, x1_o - x1_i))\n",
    "    uniq = list(set(shifts))\n",
    "    if len(uniq) == 1:\n",
    "        result["type"] = "translation"\n",
    "        result["shift"] = uniq[0]\n",
    "        return result\n",
    "\n",
    "    return result\n",
    "# write to /kaggle/working/arc_solver/step2_compare.py",
    "open('/kaggle/working/arc_solver/step2_compare.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step2_compare.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "# step2_geometry.py — geometric pattern analyzer for ARC tasks\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def rotate90(a: np.ndarray, k: int = 1) -> np.ndarray:\n",
    "    """Rotate grid 90° × k times clockwise."""\n",
    "    return np.rot90(a, -k)\n",
    "\n",
    "def flip_x(a: np.ndarray) -> np.ndarray:\n",
    "    """Flip grid horizontally."""\n",
    "    return np.fliplr(a)\n",
    "\n",
    "def flip_y(a: np.ndarray) -> np.ndarray:\n",
    "    """Flip grid vertically."""\n",
    "    return np.flipud(a)\n",
    "\n",
    "def transpose(a: np.ndarray) -> np.ndarray:\n",
    "    """Transpose grid (swap axes)."""\n",
    "    return a.T\n",
    "\n",
    "def best_geometric_transform(inp: np.ndarray, out: np.ndarray) -> tuple[str, np.ndarray, float]:\n",
    "    """Try all transforms and return (name, transformed, match_score)."""\n",
    "    cands = {\n",
    "        "none": inp,\n",
    "        "rot90": rotate90(inp),\n",
    "        "rot180": rotate90(inp, 2),\n",
    "        "rot270": rotate90(inp, 3),\n",
    "        "flip_x": flip_x(inp),\n",
    "        "flip_y": flip_y(inp),\n",
    "        "transpose": transpose(inp),\n",
    "    }\n",
    "    best_name, best_score, best_img = "none", 0.0, inp\n",
    "    for name, img in cands.items():\n",
    "        s = (img.shape == out.shape)\n",
    "        score = 0.0\n",
    "        if s:\n",
    "            score = np.mean(img == out)\n",
    "        if score > best_score:\n",
    "            best_name, best_score, best_img = name, score, img\n",
    "    return best_name, best_img, round(float(best_score), 3)\n",
    "# write to /kaggle/working/arc_solver/step2_geometry.py",
    "open('/kaggle/working/arc_solver/step2_geometry.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step2_geometry.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "# ============================================================\n",
    "# STEP 3 — Learn from training pairs\n",
    "# Fully defined, JSON-safe, NumPy-robust\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import arc_solver.step17_structural_generalizer as s17\n",
    "\n",
    "\n",
    "def learn_from_pairs(task_or_list):\n",
    "    """\n",
    "    Learn structural color patterns between input/output grids.\n",
    "    Works with:\n",
    "      • dict containing {'train': [...]}\n",
    "      • list of {'input': [...], 'output': [...]}\n",
    "\n",
    "    Returns:\n",
    "      dict {\n",
    "         'best_rule': list[int],\n",
    "         'confidence': float\n",
    "      }\n",
    "    """\n",
    "    # --- normalize input ---\n",
    "    if isinstance(task_or_list, dict):\n",
    "        train_pairs = task_or_list.get("train", [])\n",
    "    elif isinstance(task_or_list, list):\n",
    "        train_pairs = task_or_list\n",
    "    else:\n",
    "        raise TypeError(f"Unsupported type {type(task_or_list)}")\n",
    "\n",
    "    outs = []\n",
    "    confs = []\n",
    "\n",
    "    for pair in train_pairs:\n",
    "        if not isinstance(pair, dict) or "input" not in pair or "output" not in pair:\n",
    "            continue\n",
    "\n",
    "        x = np.asarray(pair["input"], dtype=np.uint8)\n",
    "        y = np.asarray(pair["output"], dtype=np.uint8)\n",
    "\n",
    "        aligned = s17.detect_structure(x, y)\n",
    "        mask = (aligned != y)\n",
    "\n",
    "        # handle shape mismatches safely\n",
    "        if mask.shape != y.shape:\n",
    "            if mask.size == y.size:\n",
    "                vals = y.ravel()[mask.ravel()]\n",
    "            else:\n",
    "                n = min(mask.size, y.size)\n",
    "                vals = y.ravel()[:n]\n",
    "        else:\n",
    "            vals = y[mask]\n",
    "\n",
    "        # ensure JSON-safe ints\n",
    "        outs.extend(int(v) for v in np.asarray(vals).ravel())\n",
    "\n",
    "        conf = 1.0 - (np.mean(mask) if mask.size else 0.0)\n",
    "        confs.append(conf)\n",
    "\n",
    "    mean_conf = float(np.mean(confs)) if confs else 0.0\n",
    "    best_rule = outs if outs else [0]\n",
    "\n",
    "    # JSON-serializable result\n",
    "    return {"best_rule": [int(v) for v in best_rule], "confidence": mean_conf}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Stand-alone test entry\n",
    "# ============================================================\n",
    "if __name__ == "__main__":\n",
    "    import sys\n",
    "    path = Path(sys.argv[1]) if len(sys.argv) > 1 else None\n",
    "    if path and path.exists():\n",
    "        print("[DEBUG] Loading sample task:", path)\n",
    "        task = json.load(open(path))\n",
    "        result = learn_from_pairs(task)\n",
    "        print(f"[OK] Learned rule len={len(result['best_rule'])}, conf={result['confidence']:.3f}")\n",
    "# write to /kaggle/working/arc_solver/step3_learn.py",
    "open('/kaggle/working/arc_solver/step3_learn.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step3_learn.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "# ============================================================\n",
    "# STEP 4 — Solve a single ARC task\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from arc_solver.step3_learn import learn_from_pairs\n",
    "\n",
    "CACHE_PATH = Path.home() / "arc_solver" / "cache.json"\n",
    "\n",
    "\n",
    "def _save_json(path, data):\n",
    "    """Safely write cache to JSON file."""\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, "w") as f:\n",
    "        # ensure everything inside is serializable\n",
    "        json.dump(_json_safe(data), f, indent=2)\n",
    "\n",
    "\n",
    "def _json_safe(obj):\n",
    "    """Recursively convert NumPy types to native JSON types."""\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: _json_safe(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, (list, tuple, set)):\n",
    "        return [_json_safe(v) for v in obj]\n",
    "    elif isinstance(obj, (np.generic,)):\n",
    "        return obj.item()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "\n",
    "def solve_task(task):\n",
    "    """\n",
    "    Given a task (dict with 'id', 'train', 'test'),\n",
    "    run learning and return (predictions, confidence).\n",
    "    """\n",
    "    task_id = task.get("id", "unknown")\n",
    "    cache = {}\n",
    "\n",
    "    if CACHE_PATH.exists():\n",
    "        try:\n",
    "            cache = json.load(open(CACHE_PATH))\n",
    "        except Exception:\n",
    "            cache = {}\n",
    "\n",
    "    # Retrieve or compute a rule\n",
    "    rule = cache.get(task_id)\n",
    "    if isinstance(rule, list):\n",
    "        # backward compatibility: wrap list inside dict\n",
    "        rule = {"best_rule": rule, "confidence": 0.5}\n",
    "    elif not isinstance(rule, dict):\n",
    "        rule = None\n",
    "\n",
    "    if rule:\n",
    "        print(f"[CACHE] Reusing rule from {task_id[:8]} conf={rule.get('confidence', 0)}")\n",
    "    else:\n",
    "        result = learn_from_pairs(task)\n",
    "        rule = {\n",
    "            "best_rule": result.get("best_rule", []),\n",
    "            "confidence": result.get("confidence", 0.0),\n",
    "        }\n",
    "        cache[task_id] = rule\n",
    "        _save_json(CACHE_PATH, cache)\n",
    "        print(f"[CACHE] Stored rule for {task_id[:8]} conf={rule['confidence']:.3f}")\n",
    "\n",
    "    preds = _predict_from_rule(task, rule)\n",
    "    return preds, float(rule.get("confidence", 0.0))\n",
    "\n",
    "\n",
    "def _predict_from_rule(task, rule):\n",
    "    """Simplified inference: replicate learned pattern."""\n",
    "    tests = task.get("test", [])\n",
    "    best_rule = rule.get("best_rule", [])\n",
    "    outputs = []\n",
    "\n",
    "    for t in tests:\n",
    "        if not isinstance(t, dict) or "input" not in t:\n",
    "            continue\n",
    "        inp = np.asarray(t["input"], dtype=np.uint8)\n",
    "        out = np.copy(inp)\n",
    "        if best_rule:\n",
    "            out = np.where(inp == 0, best_rule[0] % 10, inp)\n",
    "        outputs.append(out.tolist())\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "if __name__ == "__main__":\n",
    "    import sys\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "\n",
    "    if len(sys.argv) > 1 and Path(sys.argv[1]).exists():\n",
    "        task = json.load(open(sys.argv[1]))\n",
    "        preds, conf = solve_task(task)\n",
    "        print(f"[OK] Predictions={len(preds)} conf={conf:.3f}")\n",
    "# write to /kaggle/working/arc_solver/step4_solve.py",
    "open('/kaggle/working/arc_solver/step4_solve.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step4_solve.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# arc_solver/step5_eval.py\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "from arc_solver.step0_utils import to_np\n",
    "def print_grid(grid: List[List[int]]):\n",
    "    """Render a small ARC grid as text."""\n",
    "    for row in grid:\n",
    "        line = "".join(str(v) for v in row)\n",
    "        print(line)\n",
    "    print()\n",
    "def evaluate_task(task: Dict, preds: List[List[List[int]]]):\n",
    "    """\n",
    "    Prints train inputs/outputs and test predictions side by side.\n",
    "    """\n",
    "    print("=== TRAIN PAIRS ===")\n",
    "    for i, pair in enumerate(task["train"]):\n",
    "        print(f"Train {i}")\n",
    "        print("Input:")\n",
    "        print_grid(pair["input"])\n",
    "        print("Output:")\n",
    "        print_grid(pair["output"])\n",
    "\n",
    "    print("=== TEST RESULTS ===")\n",
    "    for i, test in enumerate(task["test"]):\n",
    "        print(f"Test {i}")\n",
    "        print("Input:")\n",
    "        print_grid(test["input"])\n",
    "        print("Attempt 1:")\n",
    "        print_grid(preds[i][0])\n",
    "        print("Attempt 2:")\n",
    "        print_grid(preds[i][1])\n",
    "# write to /kaggle/working/arc_solver/step5_eval.py",
    "open('/kaggle/working/arc_solver/step5_eval.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step5_eval.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "# step5_memory.py — persistent memory with cross-task transfer and summarization\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "MEMORY_PATH = Path(__file__).parent / "solver_memory.json"\n",
    "\n",
    "def load_memory() -> dict:\n",
    "    """Load or initialize memory."""\n",
    "    if MEMORY_PATH.exists():\n",
    "        try:\n",
    "            with open(MEMORY_PATH) as f:\n",
    "                data = json.load(f)\n",
    "                if isinstance(data, dict):\n",
    "                    return data\n",
    "        except Exception:\n",
    "            pass\n",
    "    return {}\n",
    "\n",
    "def save_memory(mem: dict):\n",
    "    """Persist memory safely with NumPy-compatible types."""\n",
    "    def _convert(obj):\n",
    "        if isinstance(obj, (np.int64, np.integer)):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, (np.floating, np.float64)):\n",
    "            return float(obj)\n",
    "        return obj\n",
    "\n",
    "    serializable = json.loads(json.dumps(mem, default=_convert))\n",
    "    with open(MEMORY_PATH, "w") as f:\n",
    "        json.dump(serializable, f, indent=2)\n",
    "\n",
    "def update_memory(rule: dict):\n",
    "    """Update memory and compute transferable weights."""\n",
    "    mem = load_memory()\n",
    "    rtype = rule.get("type", "unknown")\n",
    "    cmap = rule.get("color_map", {})\n",
    "    conf = float(rule.get("confidence", 0.0))\n",
    "\n",
    "    if rtype not in mem:\n",
    "        mem[rtype] = {"records": [], "mean_conf": 0.0, "color_map": {}}\n",
    "\n",
    "    recs = mem[rtype]["records"]\n",
    "    recs.append(conf)\n",
    "    mem[rtype]["mean_conf"] = round(float(np.mean(recs)), 3)\n",
    "\n",
    "    # merge color maps from past runs for transfer learning\n",
    "    stored_cmap = mem[rtype].get("color_map", {})\n",
    "    for k, v in cmap.items():\n",
    "        stored_cmap[str(k)] = int(v)\n",
    "    mem[rtype]["color_map"] = stored_cmap\n",
    "\n",
    "    save_memory(mem)\n",
    "    print(f"[MEM] Updated {rtype}: {mem[rtype]['mean_conf']:.3f} (records={len(recs)})")\n",
    "\n",
    "def get_best_color_map(rule_type: str):\n",
    "    """Retrieve most recent color map for reuse."""\n",
    "    mem = load_memory()\n",
    "    entry = mem.get(rule_type)\n",
    "    if not entry:\n",
    "        return None\n",
    "    cmap = entry.get("color_map", {})\n",
    "    return {int(k): int(v) for k, v in cmap.items()} if cmap else None\n",
    "\n",
    "def summarize_memory() -> float:\n",
    "    """Return mean confidence across all rule types."""\n",
    "    mem = load_memory()\n",
    "    if not mem:\n",
    "        return 0.0\n",
    "    vals = [v.get("mean_conf", 0.0) for v in mem.values() if isinstance(v, dict)]\n",
    "    return round(float(np.mean(vals)), 3) if vals else 0.0\n",
    "\n",
    "def clear_memory():\n",
    "    """Reset solver memory."""\n",
    "    if MEMORY_PATH.exists():\n",
    "        MEMORY_PATH.unlink()\n",
    "        print("[MEM] Memory cleared.")\n",
    "# write to /kaggle/working/arc_solver/step5_memory.py",
    "open('/kaggle/working/arc_solver/step5_memory.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step5_memory.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "import numpy as np\n",
    "\n",
    "def rotate90(grid: np.ndarray, k: int = 1) -> np.ndarray:\n",
    "    """Rotate grid 90° clockwise k times."""\n",
    "    return np.rot90(grid, k=-k)\n",
    "\n",
    "def flip_x(grid: np.ndarray) -> np.ndarray:\n",
    "    """Flip grid horizontally."""\n",
    "    return np.fliplr(grid)\n",
    "\n",
    "def flip_y(grid: np.ndarray) -> np.ndarray:\n",
    "    """Flip grid vertically."""\n",
    "    return np.flipud(grid)\n",
    "# write to /kaggle/working/arc_solver/step5_transforms.py",
    "open('/kaggle/working/arc_solver/step5_transforms.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step5_transforms.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "# step6_log.py — persistent observer event logger\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "LOG_PATH = Path(__file__).parent / "observer_ledger.jsonl"\n",
    "\n",
    "def log_rule(rule: dict):\n",
    "    """Append a rule entry to the ledger."""\n",
    "    event = {\n",
    "        "time": datetime.utcnow().isoformat(),\n",
    "        "type": "rule",\n",
    "        **rule\n",
    "    }\n",
    "    with open(LOG_PATH, "a") as f:\n",
    "        f.write(json.dumps(event) + "\n")\n",
    "\n",
    "def log_prediction(task_id: int, pred, target):\n",
    "    """Append a prediction comparison entry."""\n",
    "    event = {\n",
    "        "time": datetime.utcnow().isoformat(),\n",
    "        "type": "prediction",\n",
    "        "task": task_id,\n",
    "        "pred": pred,\n",
    "        "target": target\n",
    "    }\n",
    "    with open(LOG_PATH, "a") as f:\n",
    "        f.write(json.dumps(event) + "\n")\n",
    "# write to /kaggle/working/arc_solver/step6_log.py",
    "open('/kaggle/working/arc_solver/step6_log.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step6_log.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "# step6_meta_observer.py — meta-weights controller with adaptive reinforcement\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "META_PATH = Path(__file__).parent / "meta_weights.json"\n",
    "FEEDBACK_LOG = Path(__file__).parent / "meta_feedback.jsonl"\n",
    "\n",
    "def _load_weights():\n",
    "    if META_PATH.exists():\n",
    "        try:\n",
    "            with open(META_PATH) as f:\n",
    "                return json.load(f)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return {"color_map": 1.0, "geom": 1.0, "none": 1.0, "unknown": 1.0}\n",
    "\n",
    "def _save_weights(weights: dict):\n",
    "    with open(META_PATH, "w") as f:\n",
    "        json.dump(weights, f, indent=2)\n",
    "\n",
    "def log_feedback(rule_type: str, confidence: float):\n",
    "    """Record performance feedback."""\n",
    "    event = {\n",
    "        "time": datetime.utcnow().isoformat(),\n",
    "        "rule_type": rule_type,\n",
    "        "confidence": float(confidence),\n",
    "    }\n",
    "    with open(FEEDBACK_LOG, "a") as f:\n",
    "        f.write(json.dumps(event) + "\n")\n",
    "\n",
    "def _aggregate_feedback():\n",
    "    """Compute average confidence per rule type from feedback log."""\n",
    "    scores = {}\n",
    "    counts = {}\n",
    "    if not FEEDBACK_LOG.exists():\n",
    "        return {}\n",
    "    with open(FEEDBACK_LOG) as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                ev = json.loads(line)\n",
    "                t = ev["rule_type"]\n",
    "                c = ev["confidence"]\n",
    "                scores[t] = scores.get(t, 0.0) + c\n",
    "                counts[t] = counts.get(t, 0) + 1\n",
    "            except Exception:\n",
    "                continue\n",
    "    return {t: round(scores[t] / counts[t], 3) for t in scores}\n",
    "\n",
    "def update_meta_weights():\n",
    "    """Update weights using feedback-based reinforcement."""\n",
    "    weights = _load_weights()\n",
    "    feedback = _aggregate_feedback()\n",
    "\n",
    "    for t, mean_conf in feedback.items():\n",
    "        if mean_conf > 0.85:\n",
    "            weights[t] = round(min(weights.get(t, 1.0) * 1.1, 2.0), 3)\n",
    "        elif mean_conf < 0.6:\n",
    "            weights[t] = round(max(weights.get(t, 1.0) * 0.9, 0.5), 3)\n",
    "\n",
    "    _save_weights(weights)\n",
    "    print(f"[META] Updated rule weights: {weights}")\n",
    "    return weights\n",
    "\n",
    "def get_rule_weights():\n",
    "    return _load_weights()\n",
    "# write to /kaggle/working/arc_solver/step6_meta_observer.py",
    "open('/kaggle/working/arc_solver/step6_meta_observer.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step6_meta_observer.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "import json, random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "WORK = Path("/data/data/com.termux/files/home/arc_solver")\n",
    "MEM_PATH = WORK / "memory.json"\n",
    "LEDGER_PATH = WORK / "ledger.json"\n",
    "WEIGHTS_PATH = WORK / "meta_weights.json"\n",
    "\n",
    "def _load_json(path: Path):\n",
    "    if not path.exists():\n",
    "        return {}\n",
    "    try:\n",
    "        with open(path) as f:\n",
    "            return json.load(f)\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "def _save_json(path: Path, data):\n",
    "    with open(path, "w") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "def update_memory(rule_type: str, confidence: float):\n",
    "    mem = _load_json(MEM_PATH)\n",
    "    rec = mem.get(rule_type, {"count": 0, "mean": 0.0})\n",
    "    rec["count"] += 1\n",
    "    rec["mean"] = round((rec["mean"] * (rec["count"] - 1) + confidence) / rec["count"], 3)\n",
    "    mem[rule_type] = rec\n",
    "    _save_json(MEM_PATH, mem)\n",
    "    print(f"[AUTOLEARN] Memory updated {rule_type}: mean={rec['mean']:.3f}, n={rec['count']}")\n",
    "\n",
    "def log_event(rule_type: str, confidence: float):\n",
    "    entry = {"time": datetime.utcnow().isoformat(), "rule_type": rule_type, "confidence": confidence}\n",
    "    with open(LEDGER_PATH, "a") as f:\n",
    "        f.write(json.dumps(entry) + "\n")\n",
    "\n",
    "def summarize_ledger():\n",
    "    try:\n",
    "        with open(LEDGER_PATH) as f:\n",
    "            lines = [json.loads(x) for x in f if x.strip()]\n",
    "        grouped = {}\n",
    "        for e in lines:\n",
    "            r = e["rule_type"]\n",
    "            grouped.setdefault(r, []).append(e["confidence"])\n",
    "        return {r: round(float(np.mean(vals)), 3) for r, vals in grouped.items()}\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "def update_meta_weights():\n",
    "    weights = _load_json(WEIGHTS_PATH) or {"color_map": 1.0, "none": 1.0, "unknown": 1.0}\n",
    "    weights["color_map"] = round(weights["color_map"] * random.uniform(0.95, 1.05), 3)\n",
    "    weights["none"] = round(weights["none"] * random.uniform(0.95, 1.05), 3)\n",
    "    _save_json(WEIGHTS_PATH, weights)\n",
    "    print(f"[AUTOLEARN] Meta weights → {weights}")\n",
    "\n",
    "def get_rule_weights():\n",
    "    if WEIGHTS_PATH.exists():\n",
    "        try:\n",
    "            with open(WEIGHTS_PATH) as f:\n",
    "                return json.load(f)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return {"color_map": 1.0, "none": 1.0, "unknown": 1.0}\n",
    "\n",
    "# === NEW: Dynamic confidence scaling ===\n",
    "def adjust_confidence(current_conf: float, rule_type: str) -> float:\n",
    "    """Boost confidence if meta learning stabilizes or repeats."""\n",
    "    mem = _load_json(MEM_PATH)\n",
    "    rule_info = mem.get(rule_type, {})\n",
    "    mean = rule_info.get("mean", current_conf)\n",
    "    count = rule_info.get("count", 1)\n",
    "\n",
    "    # If repeated corrections, gradually increase\n",
    "    scale = 1.0 + min(count / 100.0, 0.25)\n",
    "    boosted = round(min(mean * scale, 1.0), 3)\n",
    "    print(f"[ADAPT] Dynamic scaling → {rule_type}: base={mean:.3f}, boosted={boosted:.3f}")\n",
    "    return boosted\n",
    "# write to /kaggle/working/arc_solver/step7_autolearn.py",
    "open('/kaggle/working/arc_solver/step7_autolearn.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step7_autolearn.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# arc_solver/step7_confidence.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict\n",
    "def score_confidence(pred: np.ndarray, ref: np.ndarray) -> float:\n",
    "    """0–1 similarity between prediction and reference."""\n",
    "    if pred.shape != ref.shape:\n",
    "        return 0.0\n",
    "    total = pred.size\n",
    "    correct = (pred == ref).sum()\n",
    "    return float(correct) / float(total)\n",
    "def plot_confidences(confidences: List[float], title: str = "Solver Confidence"):\n",
    "    plt.clf()\n",
    "    plt.title(title)\n",
    "    plt.xlabel("Test index")\n",
    "    plt.ylabel("Confidence")\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.plot(range(len(confidences)), confidences, marker="o", color="blue")\n",
    "    plt.pause(0.3)\n",
    "\n",
    "# write to /kaggle/working/arc_solver/step7_confidence.py",
    "open('/kaggle/working/arc_solver/step7_confidence.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step7_confidence.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "# step7_ledger_dashboard.py — combine observer + memory into a unified ledger summary\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from statistics import mean\n",
    "from arc_solver.step5_memory import load_memory, summarize_memory\n",
    "\n",
    "LEDGER_PATH = Path(__file__).parent / "observer_ledger.jsonl"\n",
    "SUMMARY_PATH = Path(__file__).parent / "ledger_summary.json"\n",
    "\n",
    "def _read_ledger():\n",
    "    """Read observer events if available."""\n",
    "    if not LEDGER_PATH.exists():\n",
    "        return []\n",
    "    lines = []\n",
    "    try:\n",
    "        with open(LEDGER_PATH) as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                try:\n",
    "                    lines.append(json.loads(line))\n",
    "                except Exception:\n",
    "                    continue\n",
    "    except Exception:\n",
    "        pass\n",
    "    return lines\n",
    "\n",
    "def _aggregate_observer(events):\n",
    "    """Aggregate mean confidence per rule type."""\n",
    "    buckets = {}\n",
    "    for e in events:\n",
    "        rtype = e.get("rule_type", "unknown")\n",
    "        conf = float(e.get("confidence", 0.0))\n",
    "        if rtype not in buckets:\n",
    "            buckets[rtype] = []\n",
    "        buckets[rtype].append(conf)\n",
    "    return {k: round(mean(v), 3) for k, v in buckets.items()} if buckets else {}\n",
    "\n",
    "def build_summary():\n",
    "    """Generate combined summary of memory and observer state."""\n",
    "    obs_events = _read_ledger()\n",
    "    obs_summary = _aggregate_observer(obs_events)\n",
    "    mem = load_memory()\n",
    "    mem_summary = {k: v.get("mean_conf", 0.0) for k, v in mem.items()}\n",
    "    combined_mean = summarize_memory()\n",
    "    data = {\n",
    "        "time": datetime.utcnow().isoformat(),\n",
    "        "observer": obs_summary,\n",
    "        "memory": mem_summary,\n",
    "        "overall_mean_conf": combined_mean,\n",
    "    }\n",
    "    with open(SUMMARY_PATH, "w") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f"[LEDGER] Summary written → {SUMMARY_PATH}")\n",
    "    return data\n",
    "\n",
    "if __name__ == "__main__":\n",
    "    build_summary()\n",
    "# write to /kaggle/working/arc_solver/step7_ledger_dashboard.py",
    "open('/kaggle/working/arc_solver/step7_ledger_dashboard.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step7_ledger_dashboard.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "# step7_task_memory.py — persistent per-task learning memory\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from statistics import mean\n",
    "\n",
    "MEMORY_PATH = Path(__file__).parent / "task_memory.json"\n",
    "\n",
    "def _load():\n",
    "    if not MEMORY_PATH.exists():\n",
    "        return {}\n",
    "    try:\n",
    "        with open(MEMORY_PATH) as f:\n",
    "            return json.load(f)\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "def _save(data):\n",
    "    with open(MEMORY_PATH, "w") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "def record_task_result(task_id: str, rule_type: str, confidence: float):\n",
    "    """Store or update task memory."""\n",
    "    memory = _load()\n",
    "    rec = memory.get(task_id, {"rule_type": rule_type, "confidences": []})\n",
    "    rec["confidences"].append(confidence)\n",
    "    rec["mean_conf"] = round(mean(rec["confidences"]), 3)\n",
    "    memory[task_id] = rec\n",
    "    _save(memory)\n",
    "    print(f"[MEM] Updated {task_id}: {rec['mean_conf']}")\n",
    "    return rec["mean_conf"]\n",
    "\n",
    "def summarize_memory():\n",
    "    """Return overall mean confidence across tasks."""\n",
    "    mem = _load()\n",
    "    if not mem:\n",
    "        return 0.0\n",
    "    vals = [r["mean_conf"] for r in mem.values() if "mean_conf" in r]\n",
    "    return round(mean(vals), 3)\n",
    "# write to /kaggle/working/arc_solver/step7_task_memory.py",
    "open('/kaggle/working/arc_solver/step7_task_memory.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step7_task_memory.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    """"\n",
    "step8_memory_cache.py — persistent cache of rules including color_map for meta learning\n",
    """"\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from hashlib import sha1\n",
    "\n",
    "WORK = Path("/data/data/com.termux/files/home/arc_solver")\n",
    "CACHE_PATH = WORK / "cache.json"\n",
    "\n",
    "def _hash_task(task: dict) -> str:\n",
    "    """Unique hash per task based on training data structure."""\n",
    "    try:\n",
    "        s = json.dumps(task["train"], sort_keys=True)\n",
    "    except Exception:\n",
    "        s = str(task)\n",
    "    return sha1(s.encode()).hexdigest()[:8]\n",
    "\n",
    "def _load_cache() -> dict:\n",
    "    if CACHE_PATH.exists():\n",
    "        try:\n",
    "            return json.loads(CACHE_PATH.read_text())\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def _save_cache(cache: dict):\n",
    "    with open(CACHE_PATH, "w") as f:\n",
    "        json.dump(cache, f, indent=2)\n",
    "\n",
    "def get_cached_rule(task: dict):\n",
    "    key = _hash_task(task)\n",
    "    cache = _load_cache()\n",
    "    if key in cache:\n",
    "        rec = cache[key]\n",
    "        print(f"[CACHE] Reusing rule from {key} conf={rec.get('confidence', 0.0)}")\n",
    "        return rec["rule"]\n",
    "    return None\n",
    "\n",
    "def update_cache(task: dict, rule: dict, conf: float):\n",
    "    """Store rule and its color_map for future meta-generalization."""\n",
    "    key = _hash_task(task)\n",
    "    cache = _load_cache()\n",
    "    cache[key] = {\n",
    "        "rule": {\n",
    "            "type": rule.get("type", "unknown"),\n",
    "            "color_map": {int(k): int(v) for k, v in rule.get("color_map", {}).items()},\n",
    "            "confidence": round(float(conf), 3)\n",
    "        }\n",
    "    }\n",
    "    _save_cache(cache)\n",
    "    print(f"[CACHE] Stored rule for {key} conf={conf:.2f}")\n",
    "# write to /kaggle/working/arc_solver/step8_memory_cache.py",
    "open('/kaggle/working/arc_solver/step8_memory_cache.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step8_memory_cache.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "# step9_cross_generalize.py — cross-task rule generalization and reuse\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from hashlib import sha1\n",
    "\n",
    "WORK = Path("/data/data/com.termux/files/home/arc_solver")\n",
    "BANK_PATH = WORK / "rule_bank.json"\n",
    "\n",
    "def _hash_grid(grid):\n",
    "    """Stable SHA1 hash of flattened grid."""\n",
    "    flat = np.array(grid, dtype=np.int64).flatten()\n",
    "    return sha1(flat.tobytes()).hexdigest()[:8]\n",
    "\n",
    "def task_signature(task):\n",
    "    """Generate a compact signature based on its training pairs."""\n",
    "    parts = []\n",
    "    for pair in task.get("train", []):\n",
    "        inp, out = np.array(pair["input"]), np.array(pair["output"])\n",
    "        parts.append(_hash_grid(inp))\n",
    "        parts.append(_hash_grid(out))\n",
    "    return sha1("".join(parts).encode()).hexdigest()[:12]\n",
    "\n",
    "def _load_bank():\n",
    "    if BANK_PATH.exists():\n",
    "        try:\n",
    "            with open(BANK_PATH) as f:\n",
    "                return json.load(f)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return {}\n",
    "\n",
    "def _save_bank(bank):\n",
    "    with open(BANK_PATH, "w") as f:\n",
    "        json.dump(bank, f, indent=2)\n",
    "\n",
    "def generalize_rule(task, new_rule):\n",
    "    """Blend with best previous rule based on similarity of signatures."""\n",
    "    bank = _load_bank()\n",
    "    sig = task_signature(task)\n",
    "    if not bank:\n",
    "        bank[sig] = new_rule\n",
    "        _save_bank(bank)\n",
    "        return new_rule\n",
    "\n",
    "    # compute hash distance (Hamming on first 12 chars)\n",
    "    best_sig, best_rule, best_score = None, None, 0\n",
    "    for s, r in bank.items():\n",
    "        sim = sum(a == b for a, b in zip(sig, s)) / 12\n",
    "        if sim > best_score:\n",
    "            best_score, best_sig, best_rule = sim, s, r\n",
    "\n",
    "    if best_rule and best_score > 0.75:\n",
    "        # merge color maps\n",
    "        cmap_new = new_rule.get("color_map", {})\n",
    "        cmap_old = best_rule.get("color_map", {})\n",
    "        merged = {**cmap_old, **cmap_new}\n",
    "        new_rule["color_map"] = merged\n",
    "        new_rule["type"] = new_rule.get("type", best_rule.get("type", "color_map"))\n",
    "        print(f"[GENERALIZE] Merged rule from {best_sig} sim={best_score:.2f}")\n",
    "\n",
    "    bank[sig] = new_rule\n",
    "    _save_bank(bank)\n",
    "    return new_rule\n",
    "# write to /kaggle/working/arc_solver/step9_cross_generalize.py",
    "open('/kaggle/working/arc_solver/step9_cross_generalize.py', 'w').write('''\n' + ''.join(open('/data/data/com.termux/files/home/arc_solver/step9_cross_generalize.py').readlines()) + '\n''')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 3. Run solver\n",
    "import sys\n",
    "sys.path.insert(0, '/kaggle/working/arc_solver')\n",
    "from arc_solver import main_pipeline\n",
    "main_pipeline.main()\n",
    "print('\\n[✓] Solver finished — submission saved to /kaggle/working/arc_solver/submission.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
